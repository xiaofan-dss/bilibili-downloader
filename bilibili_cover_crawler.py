# -*- coding: utf-8 -*-
"""
å“”å“©å“”å“©ç”¨æˆ·è§†é¢‘å°é¢çˆ¬è™«
åŠŸèƒ½ï¼šè·å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘å°é¢ï¼ŒæŒ‰ç…§BVå·å’Œæ ‡é¢˜ä¿å­˜åˆ°ä»¥ç”¨æˆ·IDå’Œç”¨æˆ·åå‘½åçš„æ–‡ä»¶å¤¹ä¸­
"""

import os
import re
import time
import json
import random
import requests
from urllib.parse import urlparse
from pathlib import Path
from tqdm import tqdm
import config


class BilibiliCoverCrawler:
    """å“”å“©å“”å“©å°é¢çˆ¬è™«ç±»"""
    
    def __init__(self):
        self.session = requests.Session()
        self.request_count = 0  # è¯·æ±‚è®¡æ•°å™¨
        self.last_request_time = 0  # ä¸Šæ¬¡è¯·æ±‚æ—¶é—´
        self.failure_count = 0  # è¿ç»­å¤±è´¥è®¡æ•°
        self.last_error_time = 0  # ä¸Šæ¬¡é”™è¯¯æ—¶é—´
        self.is_first_request = True  # æ˜¯å¦æ˜¯é¦–æ¬¡è¯·æ±‚
        self.update_headers()
        print(f"\nğŸŒ¡ï¸ åˆå§‹åŒ–çˆ¬è™«(æé™ä¿å®ˆæ¨¡å¼)ï¼Œé¢„çƒ­ç­‰å¾… {config.INITIAL_WARMUP_DELAY} ç§’...")
        with tqdm(total=config.INITIAL_WARMUP_DELAY, desc="é¢„çƒ­ä¸­", unit="s") as pbar:
            for i in range(config.INITIAL_WARMUP_DELAY):
                time.sleep(1)
                pbar.update(1)
        
    def update_headers(self):
        """æ›´æ–°è¯·æ±‚å¤´ï¼Œéšæœºé€‰æ‹©User-Agentå’ŒåŒ¹é…çš„è¯·æ±‚å¤´æ¨¡æ¿"""
        # éšæœºé€‰æ‹©User-Agent
        user_agent = random.choice(config.USER_AGENTS)
        
        # æ ¹æ®User-Agentç±»å‹é€‰æ‹©ç›¸åº”çš„è¯·æ±‚å¤´æ¨¡æ¿
        if 'Chrome' in user_agent and 'Edg' not in user_agent:
            headers_template = config.BASE_HEADERS_TEMPLATES[0]  # Chrome
        elif 'Firefox' in user_agent:
            headers_template = config.BASE_HEADERS_TEMPLATES[1]  # Firefox
        elif 'Safari' in user_agent and 'Chrome' not in user_agent:
            headers_template = config.BASE_HEADERS_TEMPLATES[2]  # Safari
        else:
            headers_template = config.BASE_HEADERS_TEMPLATES[0]  # é»˜è®¤Chrome
        
        # æ„å»ºå®Œæ•´çš„è¯·æ±‚å¤´
        headers = headers_template.copy()
        headers['User-Agent'] = user_agent
        headers['Referer'] = 'https://www.bilibili.com/'
        
        # éšæœºæ·»åŠ ä¸€äº›å¯é€‰å¤´
        if random.random() < 0.5:
            headers['Cache-Control'] = random.choice(['no-cache', 'max-age=0', 'no-store'])
        if random.random() < 0.3:
            headers['Pragma'] = 'no-cache'
        if random.random() < 0.4:
            headers['DNT'] = '1'
        
        self.session.headers.update(headers)
        print(f"ğŸ”„ æ›´æ–°è¯·æ±‚å¤´: {user_agent[:50]}...")
    
    def smart_delay(self, is_api_request=False):
        """æ™ºèƒ½å»¶è¿Ÿæœºåˆ¶"""
        # é¦–æ¬¡è¯·æ±‚çš„é¢å¤–å»¶è¿Ÿ
        if self.is_first_request:
            print(f"\nğŸ”¥ é¦–æ¬¡è¯·æ±‚ï¼Œé¢å¤–ç­‰å¾… {config.FIRST_REQUEST_DELAY} ç§’...")
            time.sleep(config.FIRST_REQUEST_DELAY)
            self.is_first_request = False
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é•¿æ—¶é—´ä¼‘æ¯
        if self.request_count > 0 and self.request_count % config.MAX_CONSECUTIVE_REQUESTS == 0:
            print(f"\nğŸ’¤ å·²è¿ç»­è¯·æ±‚ {config.MAX_CONSECUTIVE_REQUESTS} æ¬¡ï¼Œä¼‘æ¯ {config.LONG_BREAK_DURATION} ç§’...")
            with tqdm(total=config.LONG_BREAK_DURATION, desc="ä¼‘æ¯ä¸­", unit="s") as pbar:
                for i in range(config.LONG_BREAK_DURATION):
                    time.sleep(1)
                    pbar.update(1)
            self.update_headers()  # æ›´æ–°è¯·æ±‚å¤´
            self.failure_count = 0  # é‡ç½®å¤±è´¥è®¡æ•°
        
        # å¦‚æœæœ€è¿‘æœ‰é”™è¯¯ï¼Œå¢åŠ é¢å¤–å»¶è¿Ÿ
        if self.last_error_time > 0:
            time_since_error = time.time() - self.last_error_time
            if time_since_error < config.REQUEST_FAILURE_PENALTY:
                remaining_penalty = config.REQUEST_FAILURE_PENALTY - time_since_error
                if remaining_penalty > 0:
                    print(f"âš ï¸ è·ç¦»ä¸Šæ¬¡é”™è¯¯å¤ªè¿‘ï¼Œé¢å¤–ç­‰å¾… {remaining_penalty:.1f} ç§’...")
                    time.sleep(remaining_penalty)
        
        # è®¡ç®—åŸºç¡€å»¶è¿Ÿæ—¶é—´
        if is_api_request:
            base_delay = random.uniform(config.REQUEST_DELAY_MIN, config.REQUEST_DELAY_MAX)
        else:
            base_delay = random.uniform(config.DOWNLOAD_DELAY_MIN, config.DOWNLOAD_DELAY_MAX)
        
        # æ ¹æ®å¤±è´¥æ¬¡æ•°å¢åŠ å»¶è¿Ÿ
        if self.failure_count > 0:
            penalty_multiplier = 1 + (self.failure_count * 0.8)  # å¢åŠ æƒ©ç½šå€æ•°
            base_delay *= penalty_multiplier
            print(f"ğŸ˜¨ ç”±äºå¤±è´¥æ¬¡æ•° ({self.failure_count})ï¼Œå»¶è¿Ÿå¢åŠ åˆ° {base_delay:.1f} ç§’")
        
        # ç¡®ä¿ä¸ä¸Šæ¬¡è¯·æ±‚çš„é—´éš”
        elapsed = time.time() - self.last_request_time
        if elapsed < base_delay:
            actual_wait = base_delay - elapsed
            print(f"â³ ç­‰å¾… {actual_wait:.1f} ç§’...")
            time.sleep(actual_wait)
        
        self.last_request_time = time.time()
        self.request_count += 1
    
    def handle_request_error(self, error, attempt):
        """å¤„ç†è¯·æ±‚é”™è¯¯"""
        error_str = str(error)
        self.failure_count += 1
        self.last_error_time = time.time()
        
        # æ£€æµ‹å„ç§åçˆ¬é”™è¯¯
        anti_crawl_keywords = [
            "è¯·æ±‚è¿‡äºé¢‘ç¹", "429", "Too Many Requests", 
            "rate limit", "Rate Limited", "è®¿é—®é¢‘ç¹",
            "Too fast", "slow down", "é™åˆ¶"
        ]
        
        is_anti_crawl = any(keyword in error_str for keyword in anti_crawl_keywords)
        
        if is_anti_crawl:
            # é€æ¸å¢åŠ å†·å´æ—¶é—´
            cooldown = config.ERROR_COOLDOWN * (attempt + 1) * (1 + self.failure_count * 0.5)
            print(f"\nâš ï¸ æ£€æµ‹åˆ°åçˆ¬æªæ–½: {error_str}")
            print(f"ğŸ§Š å†·å´ {cooldown:.0f} ç§’ (ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œè¿ç»­å¤±è´¥{self.failure_count}æ¬¡)...")
            
            # è¿›åº¦æ¡æ˜¾ç¤ºå†·å´è¿›åº¦
            with tqdm(total=int(cooldown), desc="å†·å´ä¸­", unit="s") as pbar:
                for i in range(int(cooldown)):
                    time.sleep(1)
                    pbar.update(1)
            
            self.update_headers()  # æ›´æ–°è¯·æ±‚å¤´
            
            # å¦‚æœå¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå¢åŠ é¢å¤–å»¶è¿Ÿ
            if self.failure_count >= 3:
                extra_delay = 60 * self.failure_count
                print(f"å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œé¢å¤–ç­‰å¾… {extra_delay} ç§’...")
                time.sleep(extra_delay)
            
            return True
        
        return False
        
    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å…è®¸çš„å­—ç¬¦"""
        # ç§»é™¤Windowsä¸å…è®¸çš„å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # ç§»é™¤æ§åˆ¶å­—ç¬¦
        filename = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', filename)
        # é™åˆ¶é•¿åº¦
        if len(filename) > config.MAX_FILENAME_LENGTH:
            filename = filename[:config.MAX_FILENAME_LENGTH]
        return filename.strip()
    
    def get_user_info(self, uid):
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        for attempt in range(config.MAX_RETRIES):
            try:
                self.smart_delay(is_api_request=True)
                
                params = {
                    'mid': uid,
                    'jsonp': 'jsonp'
                }
                
                response = self.session.get(
                    config.USER_INFO_API, 
                    params=params, 
                    timeout=config.DOWNLOAD_TIMEOUT
                )
                response.raise_for_status()
                
                data = response.json()
                if data.get('code') == 0:
                    user_data = data.get('data', {})
                    self.failure_count = 0  # æˆåŠŸåé‡ç½®å¤±è´¥è®¡æ•°
                    return {
                        'name': user_data.get('name', f'ç”¨æˆ·_{uid}'),
                        'uid': uid
                    }
                else:
                    print(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    return None
                    
            except Exception as e:
                if self.handle_request_error(e, attempt):
                    continue
                if attempt < config.MAX_RETRIES - 1:
                    delay = config.RETRY_DELAY * (config.RETRY_BACKOFF ** attempt)
                    print(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•: {e}")
                    time.sleep(delay)
                else:
                    print(f"è·å–ç”¨æˆ·ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    return None
    
    def get_user_videos(self, uid):
        """è·å–ç”¨æˆ·æ‰€æœ‰è§†é¢‘ä¿¡æ¯"""
        videos = []
        page = 1
        
        print(f"å¼€å§‹è·å–ç”¨æˆ· {uid} çš„è§†é¢‘åˆ—è¡¨...")
        
        while True:
            success = False
            for attempt in range(config.MAX_RETRIES):
                try:
                    self.smart_delay(is_api_request=True)
                    
                    params = {
                        'mid': uid,
                        'ps': config.PAGE_SIZE,
                        'pn': page,
                        'order': 'pubdate',
                        'jsonp': 'jsonp'
                    }
                    
                    response = self.session.get(
                        config.USER_SPACE_API, 
                        params=params, 
                        timeout=config.DOWNLOAD_TIMEOUT
                    )
                    response.raise_for_status()
                    
                    data = response.json()
                    if data.get('code') != 0:
                        error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                        if "è¯·æ±‚è¿‡äºé¢‘ç¹" in error_msg or "429" in error_msg:
                            if self.handle_request_error(error_msg, attempt):
                                continue
                        print(f"APIé”™è¯¯: {error_msg}")
                        return videos
                    
                    page_data = data.get('data', {})
                    page_list = page_data.get('list', {})
                    vlist = page_list.get('vlist', [])
                    
                    if not vlist:
                        success = True
                        break
                    
                    # æˆåŠŸè·å–æ•°æ®åé‡ç½®å¤±è´¥è®¡æ•°
                    if self.failure_count > 0:
                        print(f"æˆåŠŸè·å–æ•°æ®ï¼Œé‡ç½®å¤±è´¥è®¡æ•° ({self.failure_count} -> 0)")
                        self.failure_count = 0
                    
                    for video in vlist:
                        video_info = {
                            'bvid': video.get('bvid', ''),
                            'title': video.get('title', ''),
                            'pic': video.get('pic', ''),
                            'created': video.get('created', 0)
                        }
                        videos.append(video_info)
                    
                    print(f"å·²è·å–ç¬¬ {page} é¡µï¼Œå…± {len(vlist)} ä¸ªè§†é¢‘")
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
                    page_info = page_list.get('page', {})
                    if page * config.PAGE_SIZE >= page_info.get('count', 0):
                        success = True
                        break
                        
                    page += 1
                    success = True
                    break
                    
                except Exception as e:
                    if self.handle_request_error(e, attempt):
                        continue
                    if attempt < config.MAX_RETRIES - 1:
                        delay = config.RETRY_DELAY * (config.RETRY_BACKOFF ** attempt)
                        print(f"è·å–ç¬¬ {page} é¡µè§†é¢‘åˆ—è¡¨å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•: {e}")
                        time.sleep(delay)
                    else:
                        print(f"è·å–ç¬¬ {page} é¡µè§†é¢‘åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        return videos
            
            if not success:
                print(f"è·å–ç¬¬ {page} é¡µå¤±è´¥ï¼Œåœæ­¢çˆ¬å–")
                break
        
        print(f"æ€»å…±è·å–åˆ° {len(videos)} ä¸ªè§†é¢‘")
        return videos
    
    def download_cover(self, pic_url, save_path):
        """ä¸‹è½½å•ä¸ªå°é¢å›¾ç‰‡"""
        for attempt in range(config.MAX_RETRIES):
            try:
                self.smart_delay(is_api_request=False)
                
                # ç¡®ä¿URLæ˜¯å®Œæ•´çš„
                if pic_url.startswith('//'):
                    pic_url = 'https:' + pic_url
                elif pic_url.startswith('/'):
                    pic_url = 'https://i0.hdslb.com' + pic_url
                
                response = self.session.get(
                    pic_url, 
                    timeout=config.DOWNLOAD_TIMEOUT,
                    stream=True
                )
                response.raise_for_status()
                
                # åˆ›å»ºç›®å½•
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                with open(save_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                
                # æˆåŠŸä¸‹è½½åé‡ç½®å¤±è´¥è®¡æ•°
                if self.failure_count > 0:
                    self.failure_count = max(0, self.failure_count - 1)
                
                return True
                
            except Exception as e:
                if self.handle_request_error(e, attempt):
                    continue
                if attempt < config.MAX_RETRIES - 1:
                    delay = config.RETRY_DELAY * (config.RETRY_BACKOFF ** attempt)
                    print(f"ä¸‹è½½å¤±è´¥ï¼Œ{delay}ç§’åç¬¬ {attempt + 2} æ¬¡é‡è¯•: {e}")
                    time.sleep(delay)
                else:
                    print(f"ä¸‹è½½å¤±è´¥ï¼Œå·²é‡è¯• {config.MAX_RETRIES} æ¬¡: {e}")
                    return False
        
        return False
    
    def get_image_extension(self, pic_url):
        """ä»URLè·å–å›¾ç‰‡æ‰©å±•å"""
        try:
            parsed = urlparse(pic_url)
            path = parsed.path
            _, ext = os.path.splitext(path)
            if ext.lower() in config.ALLOWED_IMAGE_FORMATS:
                return ext
            else:
                return '.jpg'  # é»˜è®¤æ‰©å±•å
        except:
            return '.jpg'
    
    def crawl_user_covers(self, uid):
        """çˆ¬å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘å°é¢"""
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = self.get_user_info(uid)
        if not user_info:
            print(f"æ— æ³•è·å–ç”¨æˆ· {uid} çš„ä¿¡æ¯")
            return False
        
        user_name = user_info['name']
        print(f"ç”¨æˆ·: {user_name} (UID: {uid})")
        
        # è·å–ç”¨æˆ·æ‰€æœ‰è§†é¢‘
        videos = self.get_user_videos(uid)
        if not videos:
            print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘")
            return False
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        safe_user_name = self.sanitize_filename(user_name)
        save_dir = Path(f"{uid}_{safe_user_name}")
        save_dir.mkdir(exist_ok=True)
        
        print(f"å°é¢å°†ä¿å­˜åˆ°ç›®å½•: {save_dir}")
        
        # ä¸‹è½½å°é¢
        success_count = 0
        failed_videos = []
        
        with tqdm(total=len(videos), desc="ä¸‹è½½å°é¢") as pbar:
            for video in videos:
                bvid = video['bvid']
                title = video['title']
                pic_url = video['pic']
                
                if not pic_url:
                    print(f"è§†é¢‘ {bvid} æ²¡æœ‰å°é¢URL")
                    failed_videos.append(video)
                    pbar.update(1)
                    continue
                
                # ç”Ÿæˆæ–‡ä»¶å
                safe_title = self.sanitize_filename(title)
                ext = self.get_image_extension(pic_url)
                filename = f"{bvid}_{safe_title}{ext}"
                save_path = save_dir / filename
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if save_path.exists():
                    print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}")
                    success_count += 1
                    pbar.update(1)
                    continue
                
                # ä¸‹è½½å°é¢
                if self.download_cover(pic_url, save_path):
                    success_count += 1
                    pbar.set_postfix({"æˆåŠŸ": success_count, "å¤±è´¥": len(failed_videos)})
                else:
                    failed_videos.append(video)
                
                pbar.update(1)
                # æ™ºèƒ½å»¶è¿Ÿå·²åœ¨download_coverä¸­å¤„ç†
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        print(f"\nä¸‹è½½å®Œæˆ!")
        print(f"æ€»è§†é¢‘æ•°: {len(videos)}")
        print(f"æˆåŠŸä¸‹è½½: {success_count}")
        print(f"å¤±è´¥æ•°é‡: {len(failed_videos)}")
        
        if failed_videos:
            print("\nå¤±è´¥çš„è§†é¢‘:")
            for video in failed_videos[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå¤±è´¥çš„
                print(f"  - {video['bvid']}: {video['title']}")
            if len(failed_videos) > 10:
                print(f"  ... è¿˜æœ‰ {len(failed_videos) - 10} ä¸ª")
        
        # ä¿å­˜å¤±è´¥è®°å½•
        if failed_videos:
            failed_log = save_dir / "failed_downloads.json"
            with open(failed_log, 'w', encoding='utf-8') as f:
                json.dump(failed_videos, f, ensure_ascii=False, indent=2)
            print(f"å¤±è´¥è®°å½•å·²ä¿å­˜åˆ°: {failed_log}")
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§‘â€ğŸ’» å“”å“©å“”å“©ç”¨æˆ·è§†é¢‘å°é¢çˆ¬è™« (æé™ä¿å®ˆæ¨¡å¼)")
    print("=" * 55)
    print("\nâš ï¸  é‡è¦æç¤º:")
    print("- ğŸŒ è¯¥ç¨‹åºé‡‡ç”¨æé™ä¿å®ˆæ¨¡å¼ï¼Œè¯·æ±‚é—´éš”éå¸¸é•¿")
    print("- â° APIè¯·æ±‚é—´éš”: 15-30ç§’ï¼Œå›¾ç‰‡ä¸‹è½½é—´éš”: 5-12ç§’")
    print("- ğŸ’¤ æ¯3æ¬¡è¯·æ±‚åä¼‘æ¯5åˆ†é’Ÿï¼Œé‡é”™å†·å´10åˆ†é’Ÿ")
    print("- ğŸ”¥ å¯åŠ¨é¢„çƒ­1åˆ†é’Ÿï¼Œé¦–æ¬¡è¯·æ±‚é¢å¤–ç­‰å¾…30ç§’")
    print("- ğŸŒ™ å¼ºçƒˆå»ºè®®åœ¨æ·±å¤œæˆ–æ—©æ™¨ç­‰ç½‘ç»œç©ºé—²æ—¶é—´æ®µä½¿ç”¨")
    print("\nğŸ“‹ æ—¶é—´é¢„ä¼°:")
    print("- ğŸ£ å°ç”¨æˆ·(50ä¸ªè§†é¢‘): çº¦1-2å°æ—¶")
    print("- ğŸ§ ä¸­ç­‰ç”¨æˆ·(200ä¸ªè§†é¢‘): çº¦6-8å°æ—¶")
    print("- ğŸ‹ å¤§ç”¨æˆ·(1000ä¸ªè§†é¢‘): çº¦30+å°æ—¶")
    print("\nğŸ” å¦‚æœç¨‹åºä»ç„¶å¤±è´¥ï¼Œå¯èƒ½éœ€è¦:")
    print("- â˜• ç­‰å¾…30åˆ†é’Ÿåå†è¯•")
    print("- ğŸŒ æ›´æ¢ç½‘ç»œç¯å¢ƒ(å¦‚ä½¿ç”¨æ‰‹æœºçƒ­ç‚¹)")
    print("- ğŸ•°ï¸ é€‰æ‹©ä¸åŒçš„æ—¶é—´æ®µè¯•è¯•\n")
    
    import sys
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        try:
            uid = int(sys.argv[1])
        except ValueError:
            print("ğŸ™… é”™è¯¯: æ— æ•ˆçš„UIDå‚æ•°")
            return
    else:
        # è·å–ç”¨æˆ·è¾“å…¥
        while True:
            uid_input = input("ğŸ¯ è¯·è¾“å…¥è¦çˆ¬å–çš„ç”¨æˆ·UID (æˆ–è€…è¾“å…¥ 'q' é€€å‡º): ").strip()
            if uid_input.lower() == 'q':
                print("ğŸ™‹â€â™‚ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return
            if uid_input.isdigit():
                uid = int(uid_input)
                break
            else:
                print("ğŸ™… è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—UID")
    
    # ç¡®è®¤ç»§ç»­
    confirm = input(f"\nğŸš€ å³å°†å¼€å§‹çˆ¬å–ç”¨æˆ· {uid} çš„è§†é¢‘å°é¢ï¼Œè¿™å¯èƒ½éœ€è¦éå¸¸é•¿çš„æ—¶é—´ï¼Œç»§ç»­å—? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes', 'æ˜¯']:
        print("ğŸ™‹â€â™‚ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹å¹¶å¼€å§‹çˆ¬å–
    crawler = BilibiliCoverCrawler()
    
    try:
        success = crawler.crawl_user_covers(uid)
        if success:
            print("\nğŸ‰ çˆ¬å–å®Œæˆï¼")
        else:
            print("\nğŸ˜” çˆ¬å–å¤±è´¥ï¼")
            print("\nğŸ’¡ å»ºè®®:")
            print("1. ç­‰å¾…30-60åˆ†é’Ÿåå†è¯•")
            print("2. æ›´æ¢ç½‘ç»œç¯å¢ƒ(å¦‚ä½¿ç”¨æ‰‹æœºçƒ­ç‚¹)")
            print("3. é€‰æ‹©ä¸åŒçš„æ—¶é—´æ®µ(å¦‚æ·±å¤œæˆ–æ—©æ™¨)")
            print("4. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
        print("ğŸ’¾ å·²ä¸‹è½½çš„æ–‡ä»¶å°†ä¿ç•™ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨è·³è¿‡")
    except Exception as e:
        print(f"\nğŸ˜± ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        print("\nğŸ› ï¸ æ•…éšœæ’é™¤:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. æ£€æŸ¥UIDæ˜¯å¦æ­£ç¡®")
        print("3. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("4. è”ç³»æŠ€æœ¯æ”¯æŒ")


if __name__ == "__main__":
    main()