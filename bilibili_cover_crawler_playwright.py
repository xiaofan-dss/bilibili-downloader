# -*- coding: utf-8 -*-
"""
å“”å“©å“”å“©ç”¨æˆ·è§†é¢‘å°é¢çˆ¬è™« - Playwrightç‰ˆæœ¬
åŠŸèƒ½ï¼šä½¿ç”¨Playwrightæ¨¡æ‹Ÿæµè§ˆå™¨è·å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘å°é¢
ä¼˜åŠ¿ï¼šæ›´çœŸå®çš„æµè§ˆå™¨ç¯å¢ƒï¼Œå¤§å¤§é™ä½è¢«åçˆ¬è™«ç³»ç»Ÿæ£€æµ‹çš„é£é™©
"""

import os
import re
import time
import json
import random
import asyncio
import logging
import aiohttp
import aiofiles
import subprocess
from concurrent.futures import ThreadPoolExecutor
from urllib.parse import urlparse
from pathlib import Path
from tqdm import tqdm
from playwright.async_api import async_playwright, Browser, Page, BrowserContext
import config

# åˆå§‹åŒ–æ—¥å¿—é…ç½®
logging.basicConfig(
    level=config.LOG_LEVEL,
    format=config.LOG_FORMAT,
    datefmt=config.LOG_DATE_FORMAT
)
logger = logging.getLogger(__name__)


class BilibiliVideoDownloader:
    """å“”å“©å“”å“©è§†é¢‘ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.session = None
        self.temp_dir = Path(config.VIDEO_DOWNLOAD_CONFIG['temp_dir'])
        self.output_dir = Path(config.VIDEO_DOWNLOAD_CONFIG['output_dir'])
        self.temp_dir.mkdir(exist_ok=True)
        self.output_dir.mkdir(exist_ok=True)
        
    async def init_session(self):
        """åˆå§‹åŒ–HTTPä¼šè¯"""
        if not self.session:
            import random
            
            # éšæœºé€‰æ‹©User-Agentå’Œè¯·æ±‚å¤´æ¨¡æ¿
            user_agent = random.choice(config.VIDEO_DOWNLOAD_CONFIG['user_agents'])
            headers_template = random.choice(config.VIDEO_DOWNLOAD_CONFIG['headers_templates'])
            
            # æ„å»ºè¯·æ±‚å¤´
            headers = headers_template.copy()
            headers['User-Agent'] = user_agent
            headers['Referer'] = random.choice(config.VIDEO_DOWNLOAD_CONFIG['referers'])
            
            timeout = aiohttp.ClientTimeout(total=config.VIDEO_DOWNLOAD_CONFIG['segment_timeout'])
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                headers=headers
            )
    
    async def close_session(self):
        """å…³é—­HTTPä¼šè¯"""
        if self.session:
            await self.session.close()
            self.session = None
    
    async def get_video_info(self, bvid):
        """è·å–è§†é¢‘ä¿¡æ¯"""
        try:
            await self.init_session()
            
            # æ·»åŠ åçˆ¬å»¶è¿Ÿ
            import random
            import asyncio
            delay = random.uniform(
                config.VIDEO_DOWNLOAD_CONFIG['anti_crawl']['request_delay_min'],
                config.VIDEO_DOWNLOAD_CONFIG['anti_crawl']['request_delay_max']
            )
            await asyncio.sleep(delay)
            
            url = config.VIDEO_API_CONFIG['video_info_api']
            params = {'bvid': bvid}
            
            # æ·»åŠ APIè¯·æ±‚çš„è¯·æ±‚å¤´
            headers = {
                'Referer': random.choice(config.VIDEO_DOWNLOAD_CONFIG['referers']),
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Origin': 'https://www.bilibili.com'
            }
            
            logger.debug(f"è¯·æ±‚è§†é¢‘ä¿¡æ¯: {bvid}, URL: {url}")
            
            async with self.session.get(url, params=params, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get('code') == 0:
                        logger.debug(f"æˆåŠŸè·å–è§†é¢‘ä¿¡æ¯: {bvid}")
                        return data.get('data')
                    else:
                        error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {bvid} - {error_msg}")
                        return None
                else:
                    logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {bvid} - çŠ¶æ€ç : {response.status}")
                    return None
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¼‚å¸¸: {bvid} - {e}")
            return None
    
    async def get_play_url(self, bvid, cid):
        """è·å–è§†é¢‘æ’­æ”¾URL"""
        try:
            await self.init_session()
            
            # æ·»åŠ åçˆ¬å»¶è¿Ÿ
            import random
            import asyncio
            delay = random.uniform(
                config.VIDEO_DOWNLOAD_CONFIG['anti_crawl']['request_delay_min'],
                config.VIDEO_DOWNLOAD_CONFIG['anti_crawl']['request_delay_max']
            )
            await asyncio.sleep(delay)
            
            url = config.VIDEO_API_CONFIG['play_url_api']
            params = {
                'bvid': bvid,
                'cid': cid,
                **config.VIDEO_API_CONFIG['required_params']
            }
            
            # æ·»åŠ Refererå¤´
            headers = {
                'Referer': random.choice(config.VIDEO_DOWNLOAD_CONFIG['referers']),
                'Accept': 'application/json, text/plain, */*',
                'Origin': 'https://www.bilibili.com'
            }
            
            logger.debug(f"è¯·æ±‚æ’­æ”¾URL: {bvid}, CID: {cid}")
            
            async with self.session.get(url, params=params, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get('code') == 0:
                        logger.debug(f"æˆåŠŸè·å–æ’­æ”¾URL: {bvid}")
                        return data.get('data')
                    else:
                        error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"è·å–æ’­æ”¾URLå¤±è´¥: {bvid} - {error_msg}")
                        return None
                else:
                    logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {bvid} - çŠ¶æ€ç : {response.status}")
                    return None
        except Exception as e:
            logger.error(f"è·å–æ’­æ”¾URLå¼‚å¸¸: {bvid} - {e}")
            return None
    
    async def download_segment(self, url, output_path, progress_callback=None):
        """ä¸‹è½½è§†é¢‘åˆ†æ®µ"""
        try:
            await self.init_session()
            
            # æ·»åŠ ä¸‹è½½å»¶è¿Ÿ
            import random
            import asyncio
            delay = random.uniform(1, 3)  # ä¸‹è½½é—´éš”è¾ƒçŸ­
            await asyncio.sleep(delay)
            
            headers = {
                'Referer': random.choice(config.VIDEO_DOWNLOAD_CONFIG['referers']),
                'User-Agent': random.choice(config.VIDEO_DOWNLOAD_CONFIG['user_agents']),
                'Accept': '*/*',
                'Accept-Encoding': 'identity;q=1, *;q=0'
            }
            
            logger.debug(f"å¼€å§‹ä¸‹è½½åˆ†æ®µ: {output_path.name}")
            
            async with self.session.get(url, headers=headers) as response:
                if response.status == 200:
                    total_size = int(response.headers.get('content-length', 0))
                    downloaded = 0
                    
                    async with aiofiles.open(output_path, 'wb') as f:
                        async for chunk in response.content.iter_chunked(8192):
                            await f.write(chunk)
                            downloaded += len(chunk)
                            if progress_callback:
                                progress_callback(downloaded, total_size)
                    
                    logger.debug(f"åˆ†æ®µä¸‹è½½å®Œæˆ: {output_path.name}")
                    return True
                else:
                    logger.error(f"ä¸‹è½½å¤±è´¥: {output_path.name} - çŠ¶æ€ç : {response.status}")
                    return False
        except Exception as e:
            logger.error(f"ä¸‹è½½åˆ†æ®µå¼‚å¸¸: {output_path.name} - {e}")
            return False
    
    def find_ffmpeg_path(self):
        """æŸ¥æ‰¾FFmpegè·¯å¾„ - è·¨å¹³å°æ”¯æŒ"""
        import platform
        import shutil
        import os
        
        # 1. ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è‡ªå®šä¹‰è·¯å¾„
        if config.FFMPEG_CONFIG.get('custom_path'):
            custom_path = config.FFMPEG_CONFIG['custom_path']
            if Path(custom_path).exists():
                logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰FFmpegè·¯å¾„: {custom_path}")
                return custom_path
            else:
                logger.warning(f"è‡ªå®šä¹‰FFmpegè·¯å¾„ä¸å­˜åœ¨: {custom_path}")
        
        # 2. æ£€æŸ¥PATHç¯å¢ƒå˜é‡
        system_ffmpeg = shutil.which('ffmpeg')
        if system_ffmpeg:
            logger.info(f"åœ¨PATHä¸­æ‰¾åˆ°FFmpeg: {system_ffmpeg}")
            return system_ffmpeg
        
        # 3. æ ¹æ®å¹³å°æ£€æŸ¥å¸¸è§è·¯å¾„
        system = platform.system().lower()
        if system == 'windows':
            search_paths = config.FFMPEG_CONFIG['search_paths']['windows']
        elif system == 'linux':
            search_paths = config.FFMPEG_CONFIG['search_paths']['linux']
        elif system == 'darwin':  # macOS
            search_paths = config.FFMPEG_CONFIG['search_paths']['darwin']
        else:
            logger.warning(f"æœªçŸ¥ç³»ç»Ÿç±»å‹: {system}ï¼Œä½¿ç”¨é€šç”¨æ£€æµ‹")
            search_paths = ['ffmpeg', './ffmpeg', './bin/ffmpeg']
        
        # 4. éå†æœç´¢è·¯å¾„
        for path in search_paths:
            try:
                # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„è¿›è¡Œæ£€æŸ¥
                if os.path.isabs(path):
                    check_path = Path(path)
                else:
                    # ç›¸å¯¹è·¯å¾„ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
                    check_path = Path(os.getcwd()) / path
                
                logger.debug(f"æ£€æŸ¥è·¯å¾„: {check_path}")
                
                if check_path.exists() and check_path.is_file():
                    absolute_path = str(check_path.resolve())
                    logger.info(f"åœ¨æœç´¢è·¯å¾„ä¸­æ‰¾åˆ°FFmpeg: {absolute_path}")
                    return absolute_path
                    
            except Exception as e:
                logger.debug(f"æ£€æŸ¥è·¯å¾„ {path} æ—¶å‡ºé”™: {e}")
                continue
        
        # 5. æ‰€æœ‰è·¯å¾„éƒ½æœªæ‰¾åˆ°
        logger.warning("æœªæ‰¾åˆ°FFmpegï¼Œå·²æ£€æŸ¥çš„è·¯å¾„:")
        for path in search_paths:
            try:
                if os.path.isabs(path):
                    check_path = Path(path)
                else:
                    check_path = Path(os.getcwd()) / path
                logger.warning(f"  - {check_path} (å­˜åœ¨: {check_path.exists()})")
            except:
                logger.warning(f"  - {path} (æ£€æŸ¥å¤±è´¥)")
        
        return None
        
    def show_ffmpeg_install_guide(self):
        """æ˜¾ç¤ºFFmpegå®‰è£…æŒ‡å— - è·¨å¹³å°æ”¯æŒ"""
        import platform
        
        system = platform.system().lower()
        
        print("âŒ FFmpegæœªæ‰¾åˆ°ï¼Œæ— æ³•åˆå¹¶è§†é¢‘")
        print("ğŸ“ FFmpeg å®‰è£…æŒ‡å—:")
        print()
        
        if system == 'windows':
            print("ğŸ‘¾ Windows å®‰è£…æ–¹æ³•:")
            print("  æ–¹æ³•1: åŒ…ç®¡ç†å™¨å®‰è£… (æ¨è)")
            print("    choco install ffmpeg          # Chocolatey")
            print("    scoop install ffmpeg          # Scoop")
            print("    winget install ffmpeg         # Windows Package Manager")
            print()
            print("  æ–¹æ³•2: æ‰‹åŠ¨å®‰è£…")
            print("    1. è®¿é—® https://ffmpeg.org/download.html")
            print("    2. ä¸‹è½½ Windows ç‰ˆæœ¬")
            print("    3. è§£å‹åˆ° C:\\ffmpeg")
            print("    4. å°† C:\\ffmpeg\\bin æ·»åŠ åˆ°ç³»ç»Ÿ PATH")
            print("    5. é‡å¯å‘½ä»¤è¡Œ")
            print()
            print("  æ–¹æ³•3: æ‰‹åŠ¨é…ç½®è·¯å¾„")
            print("    åœ¨ config.py ä¸­è®¾ç½®: FFMPEG_CONFIG['custom_path'] = 'C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe'")
            
        elif system == 'linux':
            print("ğŸ§ Linux å®‰è£…æ–¹æ³•:")
            print("    sudo apt install ffmpeg       # Ubuntu/Debian")
            print("    sudo yum install ffmpeg       # CentOS/RHEL")
            print("    sudo pacman -S ffmpeg         # Arch Linux")
            print("    sudo dnf install ffmpeg       # Fedora")
            print()
            print("  æˆ–æ‰‹åŠ¨é…ç½®: FFMPEG_CONFIG['custom_path'] = '/usr/local/bin/ffmpeg'")
            
        elif system == 'darwin':
            print("ğŸ macOS å®‰è£…æ–¹æ³•:")
            print("    brew install ffmpeg           # Homebrew (æ¨è)")
            print("    sudo port install ffmpeg      # MacPorts")
            print()
            print("  æˆ–æ‰‹åŠ¨é…ç½®: FFMPEG_CONFIG['custom_path'] = '/usr/local/bin/ffmpeg'")
        
        print()
        print("ğŸ“ é…ç½®æ–‡ä»¶è®¾ç½® (config.py):")
        print("  # è‡ªå®šä¹‰FFmpegè·¯å¾„")
        print("  FFMPEG_CONFIG = {")
        print("      'custom_path': '/path/to/your/ffmpeg',  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„")
        print("      'enabled': True")
        print("  }")
        print()
        print("â„¹ï¸  å®‰è£…åè¯·é‡æ–°è¿è¡Œç¨‹åºæˆ–è¿è¡Œ: python check_ffmpeg.py éªŒè¯å®‰è£…")
    
    async def merge_video_audio(self, video_path, audio_path, output_path):
        """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘ - ä½¿ç”¨é…ç½®ä¸­çš„FFmpegè·¯å¾„"""
        try:
            # æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
            if not config.FFMPEG_CONFIG.get('enabled', True):
                logger.error("FFmpegåŠŸèƒ½å·²ç¦ç”¨")
                print("âŒ FFmpegåŠŸèƒ½å·²åœ¨é…ç½®ä¸­ç¦ç”¨")
                return False
            
            # æŸ¥æ‰¾FFmpegè·¯å¾„
            ffmpeg_path = self.find_ffmpeg_path()
            if not ffmpeg_path:
                self.show_ffmpeg_install_guide()
                return False
            
            # æ„å»ºFFmpegå‘½ä»¤
            cmd = [
                ffmpeg_path, '-y',
                '-i', str(video_path),
                '-i', str(audio_path),
                '-c:v', config.FFMPEG_CONFIG.get('video_codec', 'copy'),
                '-c:a', config.FFMPEG_CONFIG.get('audio_codec', 'aac'),
                '-preset', config.FFMPEG_CONFIG.get('quality_preset', 'fast')
            ]
            
            # æ·»åŠ é¢å¤–å‚æ•°
            extra_args = config.FFMPEG_CONFIG.get('extra_args', [])
            if extra_args:
                cmd.extend(extra_args)
            
            cmd.append(str(output_path))
            
            logger.debug(f"FFmpegå‘½ä»¤: {' '.join(cmd)}")
            
            # æ‰§è¡ŒFFmpeg - ä¿®å¤å­—ç¬¦ç¼–ç é—®é¢˜
            timeout = config.FFMPEG_CONFIG.get('timeout', 300)
            # åœ¨Windowsä¸Šæ˜ç¡®æŒ‡å®šç¼–ç ä¸ºutf-8ï¼Œé¿å…GBKç¼–ç é”™è¯¯
            result = subprocess.run(cmd, 
                                   capture_output=True, 
                                   text=True, 
                                   timeout=timeout,
                                   encoding='utf-8',
                                   errors='ignore')  # å¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
            
            if result.returncode == 0:
                logger.info(f"åˆå¹¶æˆåŠŸ: {output_path}")
                return True
            else:
                logger.error(f"FFmpegåˆå¹¶å¤±è´¥ (è¿”å›ç : {result.returncode}): {result.stderr}")
                print(f"âŒ FFmpegé”™è¯¯: {result.stderr[:200]}...")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("FFmpegåˆå¹¶è¶…æ—¶")
            print("âŒ FFmpegåˆå¹¶è¶…æ—¶ï¼Œå¯èƒ½æ–‡ä»¶è¿‡å¤§")
            return False
        except Exception as e:
            logger.error(f"åˆå¹¶è§†é¢‘å¼‚å¸¸: {e}")
            print(f"âŒ åˆå¹¶å¼‚å¸¸: {e}")
            return False
    
    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶å"""
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', filename)
        if len(filename) > 100:
            filename = filename[:100]
        return filename.strip()
    
    async def download_video(self, bvid, title=None):
        """ä¸‹è½½å•ä¸ªè§†é¢‘"""
        try:
            print(f"\nğŸ“º å¼€å§‹ä¸‹è½½è§†é¢‘: {bvid}")
            
            # é¦–å…ˆæ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
            ffmpeg_path = self.find_ffmpeg_path()
            if not ffmpeg_path:
                self.show_ffmpeg_install_guide()
                return False
            
            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = await self.get_video_info(bvid)
            if not video_info:
                print(f"âš ï¸ æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {bvid}")
                return False
            
            video_title = title or video_info.get('title', bvid)
            cid = video_info['pages'][0]['cid']  # å–ç¬¬ä¸€ä¸ªP
            
            print(f"ğŸ¥ è§†é¢‘æ ‡é¢˜: {video_title}")
            print(f"ğŸ†” CID: {cid}")
            
            # è·å–æ’­æ”¾URL
            play_data = await self.get_play_url(bvid, cid)
            if not play_data:
                print(f"âš ï¸ æ— æ³•è·å–æ’­æ”¾URL: {bvid}")
                return False
            
            # é€‰æ‹©æœ€é«˜è´¨é‡çš„è§†é¢‘å’ŒéŸ³é¢‘
            dash = play_data.get('dash')
            if not dash:
                print(f"âš ï¸ ä¸æ”¯æŒDASHæ ¼å¼: {bvid}")
                return False
            
            video_streams = dash.get('video', [])
            audio_streams = dash.get('audio', [])
            
            if not video_streams or not audio_streams:
                print(f"âš ï¸ ç¼ºå°‘è§†é¢‘æˆ–éŸ³é¢‘æµ: {bvid}")
                return False
            
            # é€‰æ‹©æœ€é«˜è´¨é‡
            video_stream = max(video_streams, key=lambda x: x.get('height', 0))
            audio_stream = max(audio_streams, key=lambda x: x.get('bandwidth', 0))
            
            video_url = video_stream['baseUrl']
            audio_url = audio_stream['baseUrl']
            
            print(f"ğŸ¥ è§†é¢‘è´¨é‡: {video_stream.get('height', 'Unknown')}p")
            print(f"ğŸµ éŸ³é¢‘ç ç‡: {audio_stream.get('bandwidth', 'Unknown')}")
            
            # å‡†å¤‡æ–‡ä»¶å
            safe_title = self.sanitize_filename(video_title)
            video_temp = self.temp_dir / f"{bvid}_video.m4s"
            audio_temp = self.temp_dir / f"{bvid}_audio.m4s"
            output_file = self.output_dir / f"{bvid}_{safe_title}.mp4"
            
            if output_file.exists():
                print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_file.name}")
                return True
            
            # ä¸‹è½½è§†é¢‘å’ŒéŸ³é¢‘
            print(f"ğŸ“¥ ä¸‹è½½è§†é¢‘æµ...")
            video_success = await self.download_segment(video_url, video_temp)
            
            if video_success:
                print(f"ğŸ“¥ ä¸‹è½½éŸ³é¢‘æµ...")
                audio_success = await self.download_segment(audio_url, audio_temp)
                
                if audio_success:
                    print(f"ğŸ”§ åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
                    merge_success = await self.merge_video_audio(video_temp, audio_temp, output_file)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        if video_temp.exists():
                            video_temp.unlink()
                        if audio_temp.exists():
                            audio_temp.unlink()
                    except:
                        pass
                    
                    if merge_success:
                        print(f"âœ… ä¸‹è½½å®Œæˆ: {output_file.name}")
                        return True
                    else:
                        print(f"âŒ åˆå¹¶å¤±è´¥: {bvid}")
                        return False
                else:
                    print(f"âŒ éŸ³é¢‘ä¸‹è½½å¤±è´¥: {bvid}")
                    return False
            else:
                print(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {bvid}")
                return False
                
        except Exception as e:
            logger.error(f"ä¸‹è½½è§†é¢‘å¼‚å¸¸: {e}")
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {bvid} - {e}")
            return False


class PlaywrightBilibiliCrawler:
    """åŸºäºPlaywrightçš„å“”å“©å“”å“©å°é¢çˆ¬è™«ç±»"""
    
    def __init__(self):
        self.browser: Browser = None
        self.context: BrowserContext = None
        self.page: Page = None
        self.request_count = 0
        self.last_request_time = 0
        self.failure_count = 0
        self.last_error_time = 0
        self.is_first_request = True
        self.video_downloader = None  # è§†é¢‘ä¸‹è½½å™¨
        
    async def init_video_downloader(self):
        """åˆå§‹åŒ–è§†é¢‘ä¸‹è½½å™¨"""
        if not self.video_downloader:
            self.video_downloader = BilibiliVideoDownloader()
            
    async def close_video_downloader(self):
        """å…³é—­è§†é¢‘ä¸‹è½½å™¨"""
        if self.video_downloader:
            await self.video_downloader.close_session()
        
    async def initialize_browser(self):
        """åˆå§‹åŒ–Playwrightæµè§ˆå™¨"""
        logger.info("å¼€å§‹åˆå§‹åŒ–Playwrightæµè§ˆå™¨...")
        print(f"\nğŸš€ åˆå§‹åŒ–Playwrightæµè§ˆå™¨...")
        
        self.playwright = await async_playwright().start()
        
        # å¯åŠ¨æµè§ˆå™¨ - ä½¿ç”¨æ›´çœŸå®çš„è®¾ç½®
        self.browser = await self.playwright.chromium.launch(
            headless=config.PLAYWRIGHT_CONFIG['headless'],
            slow_mo=config.PLAYWRIGHT_CONFIG['slow_mo'],
            args=config.BROWSER_ARGS
        )
        
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ - æ›´çœŸå®çš„è®¾ç½®
        user_agent = random.choice(config.USER_AGENTS)
        logger.debug(f"ä½¿ç”¨User-Agent: {user_agent}")
        
        self.context = await self.browser.new_context(
            viewport=config.PLAYWRIGHT_CONFIG['viewport'],
            user_agent=user_agent,
            java_script_enabled=config.PLAYWRIGHT_CONFIG['java_script_enabled'],
            ignore_https_errors=config.PLAYWRIGHT_CONFIG['ignore_https_errors'],
            # æ·»åŠ æ›´çœŸå®çš„æµè§ˆå™¨ç‰¹å¾
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            geolocation={'latitude': 39.9042, 'longitude': 116.4074},  # åŒ—äº¬
            permissions=['geolocation']
        )
        
        # è®¾ç½®æ›´çœŸå®çš„è¯·æ±‚å¤´
        await self.context.set_extra_http_headers({
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'sec-ch-ua': '"Chromium";v="120", "Not_A Brand";v="8", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # åˆ›å»ºé¡µé¢
        self.page = await self.context.new_page()
        
        # è®¾ç½®è¶…æ—¶
        self.page.set_default_timeout(config.PLAYWRIGHT_CONFIG['timeout'])
        
        # æ·»åŠ åæ£€æµ‹è„šæœ¬
        await self.add_stealth_scripts()
        
        print("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # é¢„çƒ­å»¶è¿Ÿ
        print(f"ğŸŒ¡ï¸ é¢„çƒ­ç­‰å¾… {config.INITIAL_WARMUP_DELAY} ç§’...")
        with tqdm(total=config.INITIAL_WARMUP_DELAY, desc="é¢„çƒ­ä¸­", unit="s") as pbar:
            for i in range(config.INITIAL_WARMUP_DELAY):
                await asyncio.sleep(1)
                pbar.update(1)
    
    async def add_stealth_scripts(self):
        """æ·»åŠ åæ£€æµ‹è„šæœ¬"""
        logger.debug("æ·»åŠ åæ£€æµ‹è„šæœ¬...")
        
        # éšè—webdriverå±æ€§
        await self.page.add_init_script("""
        Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined,
        });
        """)
        
        # æ¨¡æ‹ŸçœŸå®ç”¨æˆ·çš„chromeå±æ€§
        await self.page.add_init_script("""
        window.chrome = {
            runtime: {},
            loadTimes: function() {},
            csi: function() {},
            app: {}
        };
        """)
        
        # æ¨¡æ‹ŸçœŸå®çš„æ’ä»¶ä¿¡æ¯
        await self.page.add_init_script("""
        Object.defineProperty(navigator, 'plugins', {
            get: () => [1, 2, 3, 4, 5],
        });
        """)
        
        # æ¨¡æ‹ŸçœŸå®çš„è¯­è¨€è®¾ç½®
        await self.page.add_init_script("""
        Object.defineProperty(navigator, 'languages', {
            get: () => ['zh-CN', 'zh', 'en'],
        });
        """)
    
    async def wait_for_page_fully_loaded(self, url_description="é¡µé¢"):
        """ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼ŒåŒ…æ‹¬JavaScriptæ¸²æŸ“"""
        logger.debug(f"ç­‰å¾…{url_description}å®Œå…¨åŠ è½½...")
        
        for attempt in range(config.MAX_WAIT_ATTEMPTS):
            try:
                # ç­‰å¾…å¤šä¸ªåŠ è½½çŠ¶æ€
                for state in config.WAIT_FOR_LOAD_STATES:
                    logger.debug(f"ç­‰å¾…åŠ è½½çŠ¶æ€: {state}")
                    await self.page.wait_for_load_state(state, timeout=30000)
                
                # é¢å¤–ç­‰å¾…JavaScriptå®Œå…¨æ‰§è¡Œ
                logger.debug(f"é¢å¤–ç­‰å¾… {config.ADDITIONAL_WAIT_TIME} ç§’ç¡®ä¿JSå®Œå…¨æ‰§è¡Œ...")
                await asyncio.sleep(config.ADDITIONAL_WAIT_TIME)
                
                # éªŒè¯é¡µé¢å†…å®¹æ˜¯å¦æ­£å¸¸åŠ è½½
                content_valid = await self.verify_page_content()
                if content_valid:
                    logger.debug(f"{url_description}åŠ è½½å®Œæˆå¹¶éªŒè¯æˆåŠŸ")
                    return True
                else:
                    logger.warning(f"{url_description}å†…å®¹éªŒè¯å¤±è´¥ï¼Œç¬¬ {attempt + 1} æ¬¡å°è¯•")
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œä¸”é…ç½®å…è®¸é‡è¯•
                    if attempt < config.MAX_WAIT_ATTEMPTS - 1 and config.CONTENT_VERIFICATION.get('retry_on_empty', False):
                        logger.info("ç­‰å¾…3ç§’åé‡æ–°åŠ è½½é¡µé¢...")
                        await asyncio.sleep(3)
                        await self.page.reload(wait_until="networkidle")
                        continue
                    else:
                        # å¦‚æœé…ç½®ä¸å…è®¸é‡è¯•ï¼Œæˆ–æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™æ¥å—å½“å‰ç»“æœ
                        if not config.CONTENT_VERIFICATION.get('retry_on_empty', False):
                            logger.info(f"{url_description}éªŒè¯å¤±è´¥ï¼Œä½†é…ç½®ä¸å…è®¸é‡è¯•ï¼Œæ¥å—å½“å‰ç»“æœ")
                            return True  # è¿”å›Tureè¡¨ç¤ºæ¥å—å½“å‰ç»“æœ
                        break
                
            except Exception as e:
                logger.warning(f"{url_description}åŠ è½½å¼‚å¸¸: {e}, ç¬¬ {attempt + 1} æ¬¡å°è¯•")
                if attempt < config.MAX_WAIT_ATTEMPTS - 1:
                    await asyncio.sleep(5)  # ç­‰å¾…5ç§’åé‡è¯•
                    continue
        
        # å¦‚æœåˆ°è¾¾è¿™é‡Œï¼Œè¯´æ˜æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†
        if config.CONTENT_VERIFICATION.get('retry_on_empty', False):
            logger.error(f"{url_description}åŠ è½½å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            return False
        else:
            logger.warning(f"{url_description}éªŒè¯æœªé€šè¿‡ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            return True
    
    async def verify_page_content(self):
        """éªŒè¯é¡µé¢å†…å®¹æ˜¯å¦æ­£å¸¸åŠ è½½"""
        try:
            page_content = await self.page.content()
            page_title = await self.page.title()
            page_url = self.page.url
            
            logger.debug(f"éªŒè¯é¡µé¢: {page_url}")
            logger.debug(f"é¡µé¢æ ‡é¢˜: {page_title}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„é”™è¯¯é¡µé¢ï¼ˆæ›´ç²¾ç¡®çš„åˆ¤æ–­ï¼‰
            # åªæœ‰å½“è¿™äº›é”™è¯¯æŒ‡ç¤ºç¬¦å‡ºç°åœ¨æ ‡é¢˜æˆ–ç‰¹å®šä½ç½®æ—¶æ‰è®¤ä¸ºæ˜¯é”™è¯¯
            title_error_indicators = [
                'ç½‘ç»œé”™è¯¯', 'é¡µé¢ä¸å­˜åœ¨', 'è®¿é—®è¢«æ‹’ç»', 'æœåŠ¡å™¨é”™è¯¯',
                'Access Denied', 'Forbidden', 'Server Error', 'Page Not Found'
            ]
            
            # æ£€æŸ¥æ ‡é¢˜ä¸­çš„é”™è¯¯æŒ‡ç¤ºç¬¦
            for indicator in title_error_indicators:
                if indicator in page_title:
                    logger.warning(f"æ ‡é¢˜ä¸­æ£€æµ‹åˆ°é”™è¯¯æŒ‡ç¤ºç¬¦: {indicator}")
                    return False
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å“”å“©å“”å“©çš„æ­£å¸¸é¡µé¢
            # é€šè¿‡æ£€æŸ¥å…³é”®æ ‡è¯†æ¥ç¡®è®¤é¡µé¢æ­£å¸¸
            bilibili_indicators = [
                'bilibili', 'bili', 'å“”å“©å“”å“©', 'space.bilibili.com',
                'bili-header', 'bili-footer', 'bili-wrapper'
            ]
            
            has_bilibili_content = any(indicator in page_content.lower() for indicator in bilibili_indicators)
            if not has_bilibili_content:
                logger.warning("é¡µé¢ä¸­æœªæ£€æµ‹åˆ°å“”å“©å“”å“©ç›¸å…³å†…å®¹")
                return False
            
            # æ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦è¶³å¤Ÿä¸°å¯Œ
            if len(page_content) < 5000:  # å¢åŠ æœ€å°é•¿åº¦è¦æ±‚
                logger.warning(f"é¡µé¢å†…å®¹è¿‡å°‘: {len(page_content)} å­—ç¬¦ï¼Œå¯èƒ½æœªå®Œå…¨åŠ è½½")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„HTMLç»“æ„
            essential_tags = ['<html', '<body', '<head']
            for tag in essential_tags:
                if tag not in page_content:
                    logger.warning(f"ç¼ºå°‘å¿…è¦HTMLæ ‡ç­¾: {tag}")
                    return False
            
            # ç‰¹å®šé¡µé¢ç±»å‹çš„éªŒè¯
            if '/video' in page_url:
                # è§†é¢‘é¡µé¢åº”è¯¥æœ‰è§†é¢‘ç›¸å…³å†…å®¹
                video_indicators = ['.video', '.small-item', '.bili-cover', 'video-list']
                has_video_content = any(indicator in page_content for indicator in video_indicators)
                if has_video_content:
                    logger.debug("æ£€æµ‹åˆ°è§†é¢‘é¡µé¢ç›¸å…³å†…å®¹")
                else:
                    logger.info("è§†é¢‘é¡µé¢ä¸­æœªæ£€æµ‹åˆ°è§†é¢‘å†…å®¹ï¼Œå¯èƒ½æ˜¯ç©ºé¡µé¢æˆ–åŠ è½½ä¸­")
                    # ä¸ç›´æ¥è¿”å›falseï¼Œå› ä¸ºå¯èƒ½æ˜¯ç”¨æˆ·æ²¡æœ‰å…¬å¼€è§†é¢‘
            
            logger.debug(f"é¡µé¢å†…å®¹éªŒè¯é€šè¿‡ - é•¿åº¦: {len(page_content)}, æ ‡é¢˜: {page_title}")
            return True
            
        except Exception as e:
            logger.error(f"é¡µé¢å†…å®¹éªŒè¯å¼‚å¸¸: {e}")
            return False
    
    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        await self.close_video_downloader()
        if self.browser:
            await self.browser.close()
        if hasattr(self, 'playwright'):
            await self.playwright.stop()
    
    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å…è®¸çš„å­—ç¬¦"""
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', filename)
        if len(filename) > config.MAX_FILENAME_LENGTH:
            filename = filename[:config.MAX_FILENAME_LENGTH]
        return filename.strip()
    
    async def smart_delay(self, is_api_request=False):
        """æ™ºèƒ½å»¶è¿Ÿæœºåˆ¶"""
        # é¦–æ¬¡è¯·æ±‚çš„é¢å¤–å»¶è¿Ÿ
        if self.is_first_request:
            print(f"\nğŸ”¥ é¦–æ¬¡è¯·æ±‚ï¼Œé¢å¤–ç­‰å¾… {config.FIRST_REQUEST_DELAY} ç§’...")
            await asyncio.sleep(config.FIRST_REQUEST_DELAY)
            self.is_first_request = False
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é•¿æ—¶é—´ä¼‘æ¯
        if self.request_count > 0 and self.request_count % config.MAX_CONSECUTIVE_REQUESTS == 0:
            print(f"\nğŸ’¤ å·²è¿ç»­è¯·æ±‚ {config.MAX_CONSECUTIVE_REQUESTS} æ¬¡ï¼Œä¼‘æ¯ {config.LONG_BREAK_DURATION} ç§’...")
            with tqdm(total=config.LONG_BREAK_DURATION, desc="ä¼‘æ¯ä¸­", unit="s") as pbar:
                for i in range(config.LONG_BREAK_DURATION):
                    await asyncio.sleep(1)
                    pbar.update(1)
            
            # æ›´æ–°æµè§ˆå™¨ä¸Šä¸‹æ–‡
            await self.update_browser_context()
            self.failure_count = 0
        
        # å¦‚æœæœ€è¿‘æœ‰é”™è¯¯ï¼Œå¢åŠ é¢å¤–å»¶è¿Ÿ
        if self.last_error_time > 0:
            time_since_error = time.time() - self.last_error_time
            if time_since_error < config.REQUEST_FAILURE_PENALTY:
                remaining_penalty = config.REQUEST_FAILURE_PENALTY - time_since_error
                if remaining_penalty > 0:
                    print(f"âš ï¸ è·ç¦»ä¸Šæ¬¡é”™è¯¯å¤ªè¿‘ï¼Œé¢å¤–ç­‰å¾… {remaining_penalty:.1f} ç§’...")
                    await asyncio.sleep(remaining_penalty)
        
        # è®¡ç®—åŸºç¡€å»¶è¿Ÿæ—¶é—´
        if is_api_request:
            base_delay = random.uniform(config.REQUEST_DELAY_MIN, config.REQUEST_DELAY_MAX)
        else:
            base_delay = random.uniform(config.DOWNLOAD_DELAY_MIN, config.DOWNLOAD_DELAY_MAX)
        
        # æ ¹æ®å¤±è´¥æ¬¡æ•°å¢åŠ å»¶è¿Ÿ
        if self.failure_count > 0:
            penalty_multiplier = 1 + (self.failure_count * 0.5)
            base_delay *= penalty_multiplier
            print(f"ğŸ˜° ç”±äºå¤±è´¥æ¬¡æ•° ({self.failure_count})ï¼Œå»¶è¿Ÿå¢åŠ åˆ° {base_delay:.1f} ç§’")
        
        # ç¡®ä¿ä¸ä¸Šæ¬¡è¯·æ±‚çš„é—´éš”
        elapsed = time.time() - self.last_request_time
        if elapsed < base_delay:
            actual_wait = base_delay - elapsed
            print(f"â³ ç­‰å¾… {actual_wait:.1f} ç§’...")
            await asyncio.sleep(actual_wait)
        
        self.last_request_time = time.time()
        self.request_count += 1
    
    async def update_browser_context(self):
        """æ›´æ–°æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆç›¸å½“äºæ›´æ¢èº«ä»½ï¼‰"""
        print("ğŸ”„ æ›´æ–°æµè§ˆå™¨ä¸Šä¸‹æ–‡...")
        
        # å…³é—­å½“å‰é¡µé¢
        if self.page:
            await self.page.close()
        
        # å…³é—­å½“å‰ä¸Šä¸‹æ–‡
        if self.context:
            await self.context.close()
        
        # åˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡
        self.context = await self.browser.new_context(
            viewport=config.PLAYWRIGHT_CONFIG['viewport'],
            user_agent=random.choice(config.USER_AGENTS),
            java_script_enabled=config.PLAYWRIGHT_CONFIG['java_script_enabled'],
            ignore_https_errors=config.PLAYWRIGHT_CONFIG['ignore_https_errors']
        )
        
        # è®¾ç½®éšæœºçš„é¢å¤–è¯·æ±‚å¤´
        extra_headers = {
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br'
        }
        
        if random.random() < 0.5:
            extra_headers['Cache-Control'] = random.choice(['no-cache', 'max-age=0'])
        if random.random() < 0.3:
            extra_headers['Pragma'] = 'no-cache'
        if random.random() < 0.4:
            extra_headers['DNT'] = '1'
        
        await self.context.set_extra_http_headers(extra_headers)
        
        # åˆ›å»ºæ–°é¡µé¢
        self.page = await self.context.new_page()
        self.page.set_default_timeout(config.PLAYWRIGHT_CONFIG['timeout'])
    
    async def handle_request_error(self, error, attempt):
        """å¤„ç†è¯·æ±‚é”™è¯¯"""
        error_str = str(error)
        self.failure_count += 1
        self.last_error_time = time.time()
        
        # æ£€æµ‹å„ç§åçˆ¬é”™è¯¯
        anti_crawl_keywords = [
            "è¯·æ±‚è¿‡äºé¢‘ç¹", "429", "Too Many Requests", 
            "rate limit", "Rate Limited", "è®¿é—®é¢‘ç¹",
            "Too fast", "slow down", "é™åˆ¶", "blocked"
        ]
        
        is_anti_crawl = any(keyword in error_str for keyword in anti_crawl_keywords)
        
        if is_anti_crawl:
            # é€æ¸å¢åŠ å†·å´æ—¶é—´
            cooldown = config.ERROR_COOLDOWN * (attempt + 1) * (1 + self.failure_count * 0.3)
            print(f"\nâš ï¸ æ£€æµ‹åˆ°åçˆ¬æªæ–½: {error_str}")
            print(f"ğŸ§Š å†·å´ {cooldown:.0f} ç§’ (ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œè¿ç»­å¤±è´¥{self.failure_count}æ¬¡)...")
            
            # è¿›åº¦æ¡æ˜¾ç¤ºå†·å´è¿›åº¦
            with tqdm(total=int(cooldown), desc="å†·å´ä¸­", unit="s") as pbar:
                for i in range(int(cooldown)):
                    await asyncio.sleep(1)
                    pbar.update(1)
            
            # æ›´æ–°æµè§ˆå™¨ä¸Šä¸‹æ–‡
            await self.update_browser_context()
            
            return True
        
        return False
    
    async def get_user_info(self, uid):
        """ä»ç”¨æˆ·ç©ºé—´é¡µé¢è·å–ç”¨æˆ·ä¿¡æ¯"""
        for attempt in range(config.MAX_RETRIES):
            try:
                await self.smart_delay(is_api_request=True)
                
                # æ„å»ºç”¨æˆ·ç©ºé—´é¡µé¢URL
                space_url = config.USER_SPACE_BASE.format(uid=uid)
                print(f"ğŸŒ è®¿é—®ç”¨æˆ·ç©ºé—´é¡µé¢: {space_url}")
                
                # è®¿é—®ç”¨æˆ·ç©ºé—´é¡µé¢
                response = await self.page.goto(space_url, wait_until="networkidle")
                
                if response.status != 200:
                    raise Exception(f"HTTP {response.status}")
                
                # ä½¿ç”¨æ–°çš„é¡µé¢ç­‰å¾…æœºåˆ¶
                if not await self.wait_for_page_fully_loaded("ç”¨æˆ·ç©ºé—´é¡µé¢"):
                    raise Exception("é¡µé¢åŠ è½½å¤±è´¥æˆ–å†…å®¹å¼‚å¸¸")
                
                # è·å–é¡µé¢å†…å®¹ç”¨äºè°ƒè¯•
                page_content = await self.page.content()
                
                # Debugæ—¥å¿—ï¼šæ˜¾ç¤ºHTMLä¿¡æ¯
                if config.ENABLE_HTML_DEBUG and logger.isEnabledFor(logging.DEBUG):
                    html_preview = page_content[:config.HTML_DEBUG_MAX_LENGTH]
                    logger.debug(f"ç”¨æˆ·ç©ºé—´é¡µé¢HTMLå†…å®¹é¢„è§ˆ (å‰{config.HTML_DEBUG_MAX_LENGTH}å­—ç¬¦):\n{html_preview}")
                    logger.debug(f"é¡µé¢æ ‡é¢˜: {await self.page.title()}")
                    logger.debug(f"é¡µé¢URL: {self.page.url}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç§äººæˆ–ä¸å­˜åœ¨çš„ç”¨æˆ·
                if "ç”¨æˆ·ä¸å­˜åœ¨" in page_content or "è¯¥ç”¨æˆ·éšç§è®¾ç½®" in page_content or "è´¦å·å°ç¦" in page_content:
                    logger.warning(f"ç”¨æˆ· {uid} ä¸å­˜åœ¨ã€è®¾ç½®ä¸ºç§äººæˆ–å·²è¢«å°ç¦")
                    print(f"âš ï¸ ç”¨æˆ· {uid} ä¸å­˜åœ¨ã€è®¾ç½®ä¸ºç§äººæˆ–å·²è¢«å°ç¦")
                    return None
                
                # å°è¯•è·å–ç”¨æˆ·å
                user_name = None
                
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ç”¨æˆ·åé€‰æ‹©å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨ .nicknameï¼‰
                for selector in config.USER_NAME_SELECTORS:
                    try:
                        name_element = await self.page.wait_for_selector(selector, timeout=5000)
                        if name_element:
                            user_name = await name_element.text_content()
                            if user_name and user_name.strip():
                                user_name = user_name.strip()
                                logger.debug(f"é€šè¿‡é€‰æ‹©å™¨ '{selector}' è·å–åˆ°ç”¨æˆ·å: {user_name}")
                                print(f"âœ… é€šè¿‡é€‰æ‹©å™¨ '{selector}' è·å–åˆ°ç”¨æˆ·å: {user_name}")
                                if selector == '.nickname':
                                    logger.info(f"ä½¿ç”¨ nickname é€‰æ‹©å™¨æˆåŠŸè·å–ç”¨æˆ·å: {user_name}")
                                break
                    except Exception as e:
                        logger.debug(f"é€‰æ‹©å™¨ '{selector}' è·å–ç”¨æˆ·åå¤±è´¥: {e}")
                        continue
                
                # å¦‚æœæ²¡æœ‰è·å–åˆ°ç”¨æˆ·åï¼Œä½¿ç”¨é»˜è®¤åç§°
                if not user_name:
                    user_name = f'ç”¨æˆ·_{uid}'
                    print(f"âš ï¸ æœªè·å–åˆ°ç”¨æˆ·åï¼Œä½¿ç”¨é»˜è®¤åç§°: {user_name}")
                
                self.failure_count = 0  # æˆåŠŸåé‡ç½®å¤±è´¥è®¡æ•°
                print(f"âœ… æˆåŠŸè·å–ç”¨æˆ·ä¿¡æ¯: {user_name}")
                
                return {
                    'name': user_name,
                    'uid': uid
                }
                    
            except Exception as e:
                if await self.handle_request_error(e, attempt):
                    continue
                if attempt < config.MAX_RETRIES - 1:
                    delay = config.RETRY_DELAY * (config.RETRY_BACKOFF ** attempt)
                    print(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•: {e}")
                    await asyncio.sleep(delay)
                else:
                    print(f"è·å–ç”¨æˆ·ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    return None
    
    async def scroll_and_collect_videos(self):
        """æ»šåŠ¨é¡µé¢å¹¶æ”¶é›†æ‰€æœ‰è§†é¢‘ä¿¡æ¯ï¼Œæ”¯æŒåˆ†é¡µç‚¹å‡»"""
        videos = []
        collected_bvids = set()  # ç”¨äºå»é‡
        current_page = 1
        
        print(f"ğŸ”„ å¼€å§‹æ”¶é›†è§†é¢‘ä¿¡æ¯ï¼Œæ”¯æŒåˆ†é¡µå’Œæ»šåŠ¨åŠ è½½...")
        
        # ç­‰å¾…åˆå§‹è§†é¢‘åŠ è½½
        await asyncio.sleep(3)
        
        while True:
            print(f"ğŸ“„ å¤„ç†ç¬¬ {current_page} é¡µ...")
            
            # åœ¨å½“å‰é¡µé¢æ»šåŠ¨æ”¶é›†è§†é¢‘
            page_videos = await self.collect_videos_from_current_page()
            
            # æ·»åŠ æ–°è§†é¢‘åˆ°æ€»åˆ—è¡¨
            new_videos_count = 0
            for video in page_videos:
                if video['bvid'] not in collected_bvids:
                    videos.append(video)
                    collected_bvids.add(video['bvid'])
                    new_videos_count += 1
            
            print(f"ğŸ“º ç¬¬ {current_page} é¡µè·å–åˆ° {new_videos_count} ä¸ªæ–°è§†é¢‘ï¼Œæ€»è®¡ {len(videos)} ä¸ª")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ”¶é›†åˆ°äº†æœŸæœ›çš„è§†é¢‘æ•°é‡ï¼ˆæ™ºèƒ½åœæ­¢ï¼‰
            if config.PAGINATION_CONFIG.get('smart_stop', True):
                expected_count = await self.get_expected_video_count()
                if expected_count and len(videos) >= expected_count:
                    print(f"âœ… å·²æ”¶é›†åˆ°æœŸæœ›æ•°é‡ï¼ˆ{len(videos)}/{expected_count}ï¼‰ï¼Œæ— éœ€ç»§ç»­æŸ¥æ‰¾ä¸‹ä¸€é¡µ")
                    logger.info(f"æ™ºèƒ½åœæ­¢ï¼šå·²æ”¶é›†åˆ°æœŸæœ›æ•°é‡ {len(videos)}/{expected_count}")
                    break
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            has_next_page = await self.check_and_click_next_page()
            if not has_next_page:
                print(f"ğŸ å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œåœæ­¢æ”¶é›†")
                break
            
            current_page += 1
            
            # é¡µé¢åˆ‡æ¢åç­‰å¾…åŠ è½½
            print(f"â³ ç­‰å¾…ç¬¬ {current_page} é¡µåŠ è½½...")
            await asyncio.sleep(5)
        
        print(f"ğŸ‰ æ”¶é›†å®Œæˆï¼Œå…± {current_page} é¡µï¼Œæ”¶é›†åˆ° {len(videos)} ä¸ªè§†é¢‘")
        
        # éªŒè¯è§†é¢‘æ•°é‡æ˜¯å¦æ­£ç¡®
        if config.CONTENT_VERIFICATION.get('verify_video_count', False):
            expected_count = await self.get_expected_video_count()
            if expected_count:
                if len(videos) >= expected_count:
                    print(f"âœ… æ•°é‡éªŒè¯é€šè¿‡ï¼æ”¶é›†åˆ° {len(videos)} ä¸ªï¼ŒæœŸæœ› {expected_count} ä¸ª")
                else:
                    print(f"âš ï¸ æ•°é‡ä¸è¶³ï¼šæ”¶é›†åˆ° {len(videos)} ä¸ªï¼ŒæœŸæœ› {expected_count} ä¸ª")
            await self.verify_video_count(len(videos))
        
        return videos
    
    async def collect_videos_from_current_page(self):
        """ä»å½“å‰é¡µé¢æ»šåŠ¨æ”¶é›†è§†é¢‘"""
        page_videos = []
        collected_bvids = set()
        scroll_count = 0
        no_new_videos_count = 0
        
        print(f"ğŸ”„ å¼€å§‹æ»šåŠ¨æ”¶é›†å½“å‰é¡µè§†é¢‘...")
        
        while scroll_count < config.MAX_SCROLL_ATTEMPTS:
            try:
                # è·å–å½“å‰é¡µé¢çš„è§†é¢‘å°é¢å…ƒç´ ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„é€‰æ‹©å™¨ï¼‰
                video_elements = []
                for selector in config.VIDEO_SELECTORS:
                    elements = await self.page.query_selector_all(selector)
                    if elements:
                        video_elements = elements
                        logger.debug(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                        break
                    else:
                        logger.debug(f"é€‰æ‹©å™¨ '{selector}' æœªæ‰¾åˆ°å…ƒç´ ")
                
                if not video_elements:
                    print(f"âš ï¸ æœªæ‰¾åˆ°è§†é¢‘å…ƒç´ ï¼Œå°è¯•ç»§ç»­æ»šåŠ¨...")
                    await self.page.evaluate(f"window.scrollBy(0, {config.SCROLL_STEP})")
                    await asyncio.sleep(2)
                    scroll_count += 1
                    continue
                
                # è®°å½•å½“å‰è§†é¢‘æ•°é‡
                current_videos_count = len(page_videos)
                
                # æå–è§†é¢‘ä¿¡æ¯
                for element in video_elements:
                    try:
                        video_info = await self.extract_video_info(element)
                        if video_info and video_info['bvid'] not in collected_bvids:
                            page_videos.append(video_info)
                            collected_bvids.add(video_info['bvid'])
                    except Exception as e:
                        # å¿½ç•¥å•ä¸ªè§†é¢‘çš„è§£æé”™è¯¯
                        continue
                
                new_videos_count = len(page_videos) - current_videos_count
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°è§†é¢‘
                if new_videos_count == 0:
                    no_new_videos_count += 1
                    if no_new_videos_count >= 5:  # è¿ç»­5æ¬¡æ²¡æœ‰æ–°è§†é¢‘ï¼Œåœæ­¢æ»šåŠ¨
                        print(f"ğŸ˜ª è¿ç»­ {no_new_videos_count} æ¬¡æ²¡æœ‰æ–°è§†é¢‘ï¼Œå½“å‰é¡µæ»šåŠ¨å®Œæˆ")
                        break
                    # print(f"âš ï¸ æœ¬æ¬¡æ»šåŠ¨æ²¡æœ‰æ–°è§†é¢‘ï¼Œç»§ç»­å°è¯•... ({no_new_videos_count}/5)")
                else:
                    no_new_videos_count = 0
                    if new_videos_count > 0:
                        print(f"ğŸ“º æœ¬æ¬¡æ»šåŠ¨è·å–åˆ° {new_videos_count} ä¸ªæ–°è§†é¢‘ï¼Œå½“å‰é¡µæ€»è®¡ {len(page_videos)} ä¸ª")
                
                # æ£€æŸ¥æ˜¯å¦å·²åˆ°è¾¾é¡µé¢åº•éƒ¨
                is_at_bottom = await self.page.evaluate("""
                    () => {
                        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
                        const windowHeight = window.innerHeight;
                        const documentHeight = document.documentElement.scrollHeight;
                        return scrollTop + windowHeight >= documentHeight - 1000;
                    }
                """)
                
                if is_at_bottom:
                    print(f"ğŸ å½“å‰é¡µå·²åˆ°è¾¾åº•éƒ¨ï¼Œåœæ­¢æ»šåŠ¨")
                    break
                
                # æ¨¡æ‹ŸçœŸå®ç”¨æˆ·æ»šåŠ¨è¡Œä¸º
                scroll_distance = random.randint(600, 1200)  # éšæœºæ»šåŠ¨è·ç¦»
                await self.page.evaluate(f"window.scrollBy(0, {scroll_distance})")
                scroll_count += 1
                
                # éšæœºç­‰å¾…æ—¶é—´ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·
                wait_time = random.uniform(1.0, 2.5)
                await asyncio.sleep(wait_time)
                
            except Exception as e:
                print(f"âš ï¸ æ»šåŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                break
        
        print(f"âœ… å½“å‰é¡µæ»šåŠ¨å®Œæˆï¼Œæ”¶é›†åˆ° {len(page_videos)} ä¸ªè§†é¢‘")
        return page_videos
    
    async def get_expected_video_count(self):
        """è·å–é¡µé¢æ˜¾ç¤ºçš„æœŸæœ›è§†é¢‘æ€»æ•°"""
        try:
            pagination_info = await self.get_pagination_info()
            if pagination_info and 'total_count' in pagination_info:
                expected_count = pagination_info['total_count']
                logger.debug(f"ä»åˆ†é¡µä¿¡æ¯è·å–åˆ°æœŸæœ›è§†é¢‘æ•°: {expected_count}")
                return expected_count
            return None
        except Exception as e:
            logger.debug(f"è·å–æœŸæœ›è§†é¢‘æ•°å¤±è´¥: {e}")
            return None
    
    async def check_and_click_next_page(self):
        """æ£€æŸ¥å¹¶ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®"""
        try:
            print(f"ğŸ” æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ...")
            
            # å¤šç§ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨
            next_page_selectors = [
                '.vui_pagenation--btn-side:has-text("ä¸‹ä¸€é¡µ")',  # "ä¸‹ä¸€é¡µ"æŒ‰é’®
                '.vui_button:has-text("ä¸‹ä¸€é¡µ")',
                'button:has-text("ä¸‹ä¸€é¡µ")',
                '.pagination-next',
                '.next-page',
                '.page-next',
                'a:has-text("ä¸‹ä¸€é¡µ")',
                '[aria-label="ä¸‹ä¸€é¡µ"]',
                '.vui_pagenation--btn-side'  # é€šç”¨çš„åˆ†é¡µä¾§è¾¹æŒ‰é’®
            ]
            
            next_button = None
            for selector in next_page_selectors:
                try:
                    # ç­‰å¾…å…ƒç´ å‡ºç°
                    next_button = await self.page.wait_for_selector(selector, timeout=5000)
                    if next_button:
                        # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç‚¹å‡»ï¼ˆä¸æ˜¯ç¦ç”¨çŠ¶æ€ï¼‰
                        is_disabled = await next_button.is_disabled()
                        if not is_disabled:
                            # è¿›ä¸€æ­¥æ£€æŸ¥æŒ‰é’®æ–‡æœ¬ç¡®è®¤æ˜¯"ä¸‹ä¸€é¡µ"
                            button_text = await next_button.text_content()
                            if button_text and ('ä¸‹ä¸€é¡µ' in button_text or 'next' in button_text.lower()):
                                logger.debug(f"æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œé€‰æ‹©å™¨: {selector}, æ–‡æœ¬: {button_text}")
                                break
                        next_button = None
                except Exception as e:
                    logger.debug(f"é€‰æ‹©å™¨ {selector} æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’®å¤±è´¥: {e}")
                    continue
            
            if next_button:
                # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                await next_button.scroll_into_view_if_needed()
                await asyncio.sleep(1)
                
                # ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®
                print(f"ğŸ‘† ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®...")
                await next_button.click()
                
                # ç­‰å¾…é¡µé¢è·³è½¬
                await asyncio.sleep(3)
                
                # ç­‰å¾…æ–°é¡µé¢åŠ è½½å®Œæˆ
                await self.wait_for_page_fully_loaded("ä¸‹ä¸€é¡µ")
                
                print(f"âœ… æˆåŠŸè·³è½¬åˆ°ä¸‹ä¸€é¡µ")
                return True
            else:
                print(f"â„¹ï¸ æœªæ‰¾åˆ°å¯ç‚¹å‡»çš„ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œå¯èƒ½å·²åˆ°è¾¾æœ€åä¸€é¡µ")
                
                # è¿›ä¸€æ­¥ç¡®è®¤ï¼šæ£€æŸ¥åˆ†é¡µä¿¡æ¯
                pagination_info = await self.get_pagination_info()
                if pagination_info:
                    current_page = pagination_info.get('current_page', 1)
                    total_pages = pagination_info.get('total_pages', 1)
                    print(f"ğŸ“Š åˆ†é¡µä¿¡æ¯: å½“å‰ç¬¬ {current_page} é¡µï¼Œå…± {total_pages} é¡µ")
                    if current_page >= total_pages:
                        print(f"ğŸ å·²åˆ°è¾¾æœ€åä¸€é¡µ ({current_page}/{total_pages})")
                
                return False
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä¸‹ä¸€é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            print(f"âš ï¸ æ£€æŸ¥ä¸‹ä¸€é¡µæ—¶å‡ºé”™: {e}")
            return False
    
    async def get_pagination_info(self):
        """è·å–åˆ†é¡µä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾åˆ†é¡µä¿¡æ¯
            pagination_selectors = [
                '.vui_pagenation-go__count',
                '.pagination-info',
                '.page-info'
            ]
            
            for selector in pagination_selectors:
                try:
                    pagination_element = await self.page.query_selector(selector)
                    if pagination_element:
                        pagination_text = await pagination_element.text_content()
                        if pagination_text:
                            # è§£æåˆ†é¡µä¿¡æ¯ "å…± X é¡µ / Y ä¸ª"
                            import re
                            match = re.search(r'å…±\s*(\d+)\s*é¡µ\s*/\s*(\d+)\s*ä¸ª', pagination_text)
                            if match:
                                total_pages = int(match.group(1))
                                total_count = int(match.group(2))
                                
                                # å°è¯•è·å–å½“å‰é¡µç 
                                current_page = 1
                                
                                # æŸ¥æ‰¾å½“å‰æ¿€æ´»çš„é¡µç æŒ‰é’®
                                active_page_selectors = [
                                    '.vui_pagenation--btn-num.vui_pagenation--btn-active',
                                    '.vui_pagenation--btn-num[class*="active"]',
                                    '.current-page',
                                    '.page-active',
                                    '.active'
                                ]
                                
                                for page_selector in active_page_selectors:
                                    try:
                                        active_element = await self.page.query_selector(page_selector)
                                        if active_element:
                                            page_text = await active_element.text_content()
                                            if page_text and page_text.isdigit():
                                                current_page = int(page_text)
                                                break
                                    except:
                                        continue
                                
                                return {
                                    'current_page': current_page,
                                    'total_pages': total_pages,
                                    'total_count': total_count,
                                    'pagination_text': pagination_text
                                }
                except Exception as e:
                    continue
            
            return None
            
        except Exception as e:
            logger.debug(f"è·å–åˆ†é¡µä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def verify_video_count(self, collected_count):
        """éªŒè¯æ”¶é›†åˆ°çš„è§†é¢‘æ•°é‡æ˜¯å¦ä¸é¡µé¢æ˜¾ç¤ºä¸€è‡´"""
        try:
            if not config.VIDEO_COUNT_VERIFICATION.get('check_pagination', False):
                logger.debug("è§†é¢‘æ•°é‡æ ¡éªŒå·²ç¦ç”¨")
                return True
            
            logger.debug("å¼€å§‹éªŒè¯è§†é¢‘æ•°é‡...")
            print(f"ğŸ” æ­£åœ¨éªŒè¯è§†é¢‘æ•°é‡...")
            
            # æŸ¥æ‰¾åˆ†é¡µä¿¡æ¯å…ƒç´ 
            pagination_text = None
            expected_count = None
            
            for selector in config.VIDEO_COUNT_VERIFICATION['pagination_selectors']:
                try:
                    pagination_element = await self.page.query_selector(selector)
                    if pagination_element:
                        pagination_text = await pagination_element.text_content()
                        if pagination_text and pagination_text.strip():
                            logger.debug(f"é€šè¿‡é€‰æ‹©å™¨ '{selector}' è·å–åˆ°åˆ†é¡µä¿¡æ¯: {pagination_text}")
                            print(f"ğŸ“Š æ‰¾åˆ°åˆ†é¡µä¿¡æ¯: {pagination_text.strip()}")
                            break
                except Exception as e:
                    logger.debug(f"é€‰æ‹©å™¨ '{selector}' è·å–åˆ†é¡µä¿¡æ¯å¤±è´¥: {e}")
                    continue
            
            if not pagination_text:
                print(f"âš ï¸ æœªæ‰¾åˆ°åˆ†é¡µä¿¡æ¯ï¼Œæ— æ³•éªŒè¯è§†é¢‘æ•°é‡")
                logger.warning("æœªæ‰¾åˆ°åˆ†é¡µä¿¡æ¯")
                return True  # ä¸å¼ºåˆ¶éªŒè¯
            
            # ä½¿ç”¨æ­£åˆ™æå–æ€»æ•°
            import re
            pattern = config.VIDEO_COUNT_VERIFICATION['count_pattern']
            match = re.search(pattern, pagination_text)
            
            if match:
                page_count = int(match.group(1))  # é¡µæ•°
                expected_count = int(match.group(2))  # æ€»è§†é¢‘æ•°
                logger.debug(f"æå–åˆ°åˆ†é¡µä¿¡æ¯: {page_count} é¡µ, {expected_count} ä¸ªè§†é¢‘")
                print(f"ğŸ“ˆ é¡µé¢æ˜¾ç¤º: å…± {page_count} é¡µ / {expected_count} ä¸ªè§†é¢‘")
            else:
                print(f"âš ï¸ æ— æ³•ä»åˆ†é¡µä¿¡æ¯ä¸­æå–æ•°é‡: {pagination_text}")
                logger.warning(f"æ­£åˆ™åŒ¹é…å¤±è´¥: {pagination_text}")
                return True  # ä¸å¼ºåˆ¶éªŒè¯
            
            if expected_count is None:
                return True
            
            # è®¡ç®—è¯¯å·®æ¯”ä¾‹
            if expected_count > 0:
                difference = abs(collected_count - expected_count)
                error_ratio = difference / expected_count
                tolerance = config.VIDEO_COUNT_VERIFICATION['tolerance_ratio']
                
                print(f"ğŸ“Š æ•°é‡å¯¹æ¯”:")
                print(f"  é¡µé¢æ˜¾ç¤º: {expected_count} ä¸ªè§†é¢‘")
                print(f"  å®é™…æ”¶é›†: {collected_count} ä¸ªè§†é¢‘")
                print(f"  å·®å¼‚æ•°é‡: {difference} ä¸ª")
                print(f"  è¯¯å·®æ¯”ä¾‹: {error_ratio:.2%} (å…è®¸è¯¯å·®: {tolerance:.2%})")
                
                if error_ratio <= tolerance:
                    print(f"âœ… è§†é¢‘æ•°é‡éªŒè¯é€šè¿‡ï¼")
                    logger.info(f"è§†é¢‘æ•°é‡éªŒè¯é€šè¿‡: æœŸæœ›{expected_count}, å®é™…{collected_count}, è¯¯å·®{error_ratio:.2%}")
                    return True
                else:
                    print(f"âš ï¸ è§†é¢‘æ•°é‡ä¸åŒ¹é…ï¼")
                    print(f"ğŸ’¡ å¯èƒ½çš„åŸå› :")
                    print(f"  1. é¡µé¢æœªå®Œå…¨åŠ è½½ï¼Œå°è¯•å¢åŠ æ»šåŠ¨æ¬¡æ•°")
                    print(f"  2. éƒ¨åˆ†è§†é¢‘è¢«è®¾ä¸ºç§äººæˆ–å·²åˆ é™¤")
                    print(f"  3. ç½‘ç»œé—®é¢˜å¯¼è‡´éƒ¨åˆ†å†…å®¹åŠ è½½å¤±è´¥")
                    print(f"  4. é¡µé¢ç»“æ„å˜åŒ–ï¼Œéœ€è¦æ›´æ–°é€‰æ‹©å™¨")
                    
                    logger.warning(f"è§†é¢‘æ•°é‡ä¸åŒ¹é…: æœŸæœ›{expected_count}, å®é™…{collected_count}, è¯¯å·®{error_ratio:.2%}")
                    
                    # è¿”å›Trueè¡¨ç¤ºç»§ç»­æ‰§è¡Œï¼Œä½†ç»™å‡ºè­¦å‘Š
                    return True
            else:
                print(f"âš ï¸ é¡µé¢æ˜¾ç¤ºè§†é¢‘æ•°ä¸º0ï¼Œæ— æ³•éªŒè¯")
                return True
                
        except Exception as e:
            logger.error(f"è§†é¢‘æ•°é‡éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            print(f"âš ï¸ è§†é¢‘æ•°é‡éªŒè¯å‡ºé”™: {e}")
            return True  # å‡ºé”™æ—¶ä¸å½±å“ä¸»æµç¨‹
    
    async def extract_video_info(self, element):
        """ä»è§†é¢‘å°é¢å…ƒç´ ä¸­æå–ä¿¡æ¯"""
        try:
            logger.debug("å¼€å§‹ä»è§†é¢‘å…ƒç´ æå–ä¿¡æ¯...")
            
            # æ£€æŸ¥å…ƒç´ ç±»å‹
            element_class = await element.get_attribute('class') or ''
            
            # ä¼˜å…ˆå¤„ç† bili-video-card å…ƒç´ 
            if 'bili-video-card' in element_class:
                logger.debug("æ£€æµ‹åˆ° bili-video-card å…ƒç´ ")
                return await self.extract_from_bili_video_card(element)
            
            # å¤„ç† bili-cover-card__thumbnail å…ƒç´ 
            if 'bili-cover-card__thumbnail' in element_class:
                logger.debug("æ£€æµ‹åˆ° bili-cover-card__thumbnail å…ƒç´ ")
                return await self.extract_from_bili_cover_card(element)
            
            # åœ¨å­å…ƒç´ ä¸­æŸ¥æ‰¾ bili-video-card
            video_card_element = await element.query_selector('.bili-video-card')
            if video_card_element:
                logger.debug("åœ¨å­å…ƒç´ ä¸­æ‰¾åˆ° bili-video-card")
                return await self.extract_from_bili_video_card(video_card_element)
            
            # åœ¨å­å…ƒç´ ä¸­æŸ¥æ‰¾ bili-cover-card__thumbnail
            thumbnail_element = await element.query_selector('.bili-cover-card__thumbnail')
            if thumbnail_element:
                logger.debug("åœ¨å­å…ƒç´ ä¸­æ‰¾åˆ° bili-cover-card__thumbnail")
                return await self.extract_from_bili_cover_card(thumbnail_element)
            
            # ä½¿ç”¨é€šç”¨æ–¹æ³•
            logger.debug("æœªæ‰¾åˆ°ç‰¹å®šå…ƒç´ ï¼Œä½¿ç”¨é€šç”¨æå–æ–¹æ³•")
            return await self.extract_generic_video_info(element)
            
        except Exception as e:
            logger.debug(f"æå–è§†é¢‘ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    async def extract_from_bili_video_card(self, element):
        """ä» bili-video-card å…ƒç´ æå–è§†é¢‘ä¿¡æ¯"""
        try:
            logger.debug("ä» bili-video-card å…ƒç´ æå–ä¿¡æ¯...")
            
            # è·å–è§†é¢‘é“¾æ¥å’ŒBVå·
            link_element = await element.query_selector('a[href*="/video/"]')
            if not link_element:
                logger.debug("åœ¨ bili-video-card ä¸­æœªæ‰¾åˆ°è§†é¢‘é“¾æ¥")
                return None
            
            href = await link_element.get_attribute('href')
            if not href:
                logger.debug("é“¾æ¥å…ƒç´ æ²¡æœ‰ href å±æ€§")
                return None
            
            # æå–BVå·
            import re
            bv_match = re.search(r'/video/(BV[A-Za-z0-9]+)', href)
            if not bv_match:
                bv_match = re.search(r'(BV[A-Za-z0-9]+)', href)
                if not bv_match:
                    logger.debug(f"æ— æ³•ä»é“¾æ¥ä¸­æå–BVå·: {href}")
                    return None
            
            bvid = bv_match.group(1)
            logger.debug(f"ä» bili-video-card æå–åˆ°BVå·: {bvid}")
            
            # è·å–æ ‡é¢˜ - ä¼˜å…ˆä½¿ç”¨ bili-video-card__title
            title = ''
            title_element = await element.query_selector('.bili-video-card__title')
            if title_element:
                # å°è¯•ä»æ ‡é¢˜å…ƒç´ è·å–æ–‡æœ¬
                title = await title_element.text_content() or ''
                if not title:
                    # å¦‚æœæ ‡é¢˜å…ƒç´ ä¸­æœ‰é“¾æ¥ï¼Œä»é“¾æ¥è·å–
                    title_link = await title_element.query_selector('a')
                    if title_link:
                        title = await title_link.text_content() or ''
                        if not title:
                            title = await title_link.get_attribute('title') or ''
                
                if title:
                    logger.debug(f"ä» bili-video-card__title è·å–æ ‡é¢˜: {title}")
            
            # å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œä»é“¾æ¥çš„titleå±æ€§è·å–
            if not title:
                title = await link_element.get_attribute('title') or ''
                if title:
                    logger.debug(f"ä»é“¾æ¥titleå±æ€§è·å–æ ‡é¢˜: {title}")
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not title:
                title = f'BV{bvid}çš„è§†é¢‘'
            
            # è·å–å°é¢å›¾ç‰‡ - ä» img å…ƒç´ è·å–
            pic = ''
            img_element = await element.query_selector('img')
            if img_element:
                pic = (await img_element.get_attribute('src') or 
                      await img_element.get_attribute('data-src') or 
                      await img_element.get_attribute('data-original') or
                      await img_element.get_attribute('lazy-src') or
                      await img_element.get_attribute('data-lazy-src') or '')
                
                if pic:
                    logger.debug(f"ä» bili-video-card img è·å–å°é¢: {pic}")
            
            # å¤„ç†å°é¢URL
            pic = self.process_image_url(pic)
            
            video_info = {
                'bvid': bvid,
                'title': title.strip(),
                'pic': pic,
                'created': int(time.time())
            }
            logger.debug(f"æˆåŠŸä» bili-video-card æå–ä¿¡æ¯: {video_info}")
            return video_info
            
        except Exception as e:
            logger.debug(f"ä» bili-video-card æå–ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    async def extract_from_bili_cover_card(self, element):
        """ä» bili-cover-card__thumbnail å…ƒç´ æå–è§†é¢‘ä¿¡æ¯"""
        try:
            logger.debug("ä» bili-cover-card__thumbnail å…ƒç´ æå–ä¿¡æ¯...")
            
            # ç›´æ¥ä» img å…ƒç´ è·å–å°é¢åœ°å€
            pic = ''
            img_element = await element.query_selector('img')
            if img_element:
                # ä¼˜å…ˆè·å– src å±æ€§ï¼Œè¿™å°±æ˜¯å°é¢åœ°å€
                pic = (await img_element.get_attribute('src') or 
                      await img_element.get_attribute('data-src') or 
                      await img_element.get_attribute('data-original') or
                      await img_element.get_attribute('lazy-src') or
                      await img_element.get_attribute('data-lazy-src') or '')
                
                if pic:
                    logger.debug(f"ä» img å…ƒç´  src è·å–å°é¢åœ°å€: {pic}")
                else:
                    # å¦‚æœæ²¡æœ‰å¸¸è§„å±æ€§ï¼Œå°è¯•ä» style è·å–èƒŒæ™¯å›¾ç‰‡
                    style = await img_element.get_attribute('style') or ''
                    if 'background-image' in style:
                        import re
                        bg_match = re.search(r'background-image:\s*url\(["\']?([^"\')]+)', style)
                        if bg_match:
                            pic = bg_match.group(1)
                            logger.debug(f"ä» img style è·å–å°é¢åœ°å€: {pic}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° imgï¼Œå°è¯• picture æ ‡ç­¾
            if not pic:
                picture_element = await element.query_selector('picture img, picture source')
                if picture_element:
                    pic = (await picture_element.get_attribute('src') or 
                          await picture_element.get_attribute('srcset') or
                          await picture_element.get_attribute('data-src') or '')
                    
                    if 'srcset' in str(pic) and pic:
                        pic = pic.split(',')[0].split(' ')[0]
                    
                    if pic:
                        logger.debug(f"ä» picture å…ƒç´ è·å–å°é¢åœ°å€: {pic}")
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•çˆ¶å…ƒç´ ä¸­çš„ img
            if not pic:
                parent_element = await element.query_selector('xpath=..')
                if parent_element:
                    parent_img = await parent_element.query_selector('img')
                    if parent_img:
                        pic = (await parent_img.get_attribute('src') or 
                              await parent_img.get_attribute('data-src') or '')
                        if pic:
                            logger.debug(f"ä»çˆ¶å…ƒç´  img è·å–å°é¢åœ°å€: {pic}")
            
            # å¦‚æœæ²¡æœ‰è·å–åˆ°å°é¢åœ°å€ï¼Œè¿”å›null
            if not pic:
                logger.debug("æœªä» bili-cover-card__thumbnail è·å–åˆ°å°é¢åœ°å€")
                return None
            
            # ç°åœ¨å°è¯•è·å–BVå·å’Œæ ‡é¢˜ï¼ˆä»é“¾æ¥å’Œç›¸å…³å…ƒç´ ä¸­ï¼‰
            link_element = None
            href = None
            
            # æŸ¥æ‰¾è§†é¢‘é“¾æ¥ï¼ˆä»çˆ¶å…ƒç´ æˆ–ç›¸é‚»å…ƒç´ ï¼‰
            parent_element = await element.query_selector('xpath=..')
            if parent_element:
                # åœ¨çˆ¶å…ƒç´ ä¸­æŸ¥æ‰¾é“¾æ¥
                parent_link = await parent_element.query_selector('a[href*="/video/"]')
                if parent_link:
                    link_element = parent_link
                    href = await parent_link.get_attribute('href')
                    logger.debug(f"åœ¨çˆ¶å…ƒç´ ä¸­æ‰¾åˆ°è§†é¢‘é“¾æ¥: {href}")
                
                # å¦‚æœæ²¡æœ‰ï¼Œåœ¨å…„å¼Ÿå…ƒç´ ä¸­æŸ¥æ‰¾
                if not href:
                    sibling_links = await element.query_selector_all('xpath=../a[contains(@href, "/video/")]')
                    if sibling_links:
                        link_element = sibling_links[0]
                        href = await link_element.get_attribute('href')
                        logger.debug(f"åœ¨å…„å¼Ÿå…ƒç´ ä¸­æ‰¾åˆ°è§†é¢‘é“¾æ¥: {href}")
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰é“¾æ¥ï¼Œå°è¯•ä»å½“å‰å…ƒç´ å‘ä¸ŠæŸ¥æ‰¾
            if not href:
                current = element
                for _ in range(3):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾3å±‚
                    try:
                        parent = await current.query_selector('xpath=..')
                        if parent:
                            link = await parent.query_selector('a[href*="/video/"]')
                            if link:
                                href = await link.get_attribute('href')
                                link_element = link
                                logger.debug(f"å‘ä¸ŠæŸ¥æ‰¾æ‰¾åˆ°è§†é¢‘é“¾æ¥: {href}")
                                break
                            current = parent
                        else:
                            break
                    except:
                        break
            
            if not href:
                logger.debug("æœªæ‰¾åˆ°è§†é¢‘é“¾æ¥ï¼Œä½†å·²è·å–åˆ°å°é¢åœ°å€")
                # å³ä½¿æ²¡æœ‰é“¾æ¥ï¼Œä¹Ÿè¿”å›å°é¢ä¿¡æ¯
                pic = self.process_image_url(pic)
                return {
                    'bvid': 'UNKNOWN',  # æš‚æ—¶æ— æ³•è·å–BVå·
                    'title': 'æœªçŸ¥æ ‡é¢˜',
                    'pic': pic,
                    'created': int(time.time())
                }
            
            # æå–BVå·
            import re
            bv_match = re.search(r'/video/(BV[A-Za-z0-9]+)', href)
            if not bv_match:
                bv_match = re.search(r'(BV[A-Za-z0-9]+)', href)
                if not bv_match:
                    logger.debug(f"æ— æ³•ä»é“¾æ¥ä¸­æå–BVå·: {href}")
                    # å³ä½¿æ²¡æœ‰BVå·ï¼Œä¹Ÿè¿”å›å°é¢
                    pic = self.process_image_url(pic)
                    return {
                        'bvid': 'UNKNOWN',
                        'title': 'æœªçŸ¥æ ‡é¢˜',
                        'pic': pic,
                        'created': int(time.time())
                    }
            
            bvid = bv_match.group(1)
            logger.debug(f"æå–åˆ°BVå·: {bvid}")
            
            # è·å–æ ‡é¢˜
            title = ''
            
            # ä» bili-cover-card__title è·å–
            parent_element = await element.query_selector('xpath=..')
            if parent_element:
                title_element = await parent_element.query_selector('.bili-cover-card__title')
                if title_element:
                    title = await title_element.text_content() or ''
                    logger.debug(f"ä» bili-cover-card__title è·å–æ ‡é¢˜: {title}")
            
            # å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œä»é“¾æ¥è·å–
            if not title and link_element:
                title = await link_element.get_attribute('title') or ''
                logger.debug(f"ä»é“¾æ¥titleå±æ€§è·å–æ ‡é¢˜: {title}")
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not title:
                title = f'BV{bvid}çš„è§†é¢‘'
            
            # å¤„ç†å°é¢URL
            pic = self.process_image_url(pic)
            logger.debug(f"æœ€ç»ˆå°é¢URL: {pic}")
            
            video_info = {
                'bvid': bvid,
                'title': title.strip(),
                'pic': pic,
                'created': int(time.time())
            }
            logger.debug(f"æˆåŠŸä» bili-cover-card__thumbnail æå–ä¿¡æ¯: {video_info}")
            return video_info
            
        except Exception as e:
            logger.debug(f"ä» bili-cover-card__thumbnail æå–ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def process_image_url(self, pic_url):
        """å¤„ç†å›¾ç‰‡URLï¼Œç¡®ä¿è·å–æœ€ä½³è´¨é‡çš„å°é¢"""
        if not pic_url:
            return ''
        
        logger.debug(f"å¤„ç†å›¾ç‰‡URL: {pic_url}")
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if pic_url.startswith('//'):
            pic_url = 'https:' + pic_url
        elif pic_url.startswith('/'):
            pic_url = 'https://i0.hdslb.com' + pic_url
        
        # ç§»é™¤URLå‚æ•°ï¼Œä¿ç•™åŸå›¾è·å–æœ€é«˜è´¨é‡
        if '@' in pic_url:
            base_url = pic_url.split('@')[0]
            logger.debug(f"ç§»é™¤URLå‚æ•°ï¼Œä» {pic_url} å˜ä¸º {base_url}")
            pic_url = base_url
        
        # å¤„ç†ç¼©ç•¥å›¾å‚æ•°ï¼Œå°è¯•è·å–é«˜æ¸…ç‰ˆæœ¬
        if '_' in pic_url and any(size in pic_url for size in ['_160x120', '_320x200', '_480x300']):
            # ç§»é™¤å°å°ºå¯¸åç¼€ï¼Œè·å–åŸå›¾
            import re
            pic_url = re.sub(r'_\d+x\d+\.(jpg|jpeg|png|webp)', r'.\1', pic_url)
            logger.debug(f"ç§»é™¤å°ºå¯¸åç¼€ï¼Œè·å–é«˜æ¸…ç‰ˆæœ¬: {pic_url}")
        
        # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡URL
        if not any(pic_url.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.webp', '.gif']):
            # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œæ·»åŠ é»˜è®¤æ‰©å±•å
            if '?' not in pic_url and '#' not in pic_url:
                pic_url += '.jpg'
                logger.debug(f"æ·»åŠ é»˜è®¤æ‰©å±•å: {pic_url}")
        
        logger.debug(f"æœ€ç»ˆå¤„ç†åçš„å›¾ç‰‡URL: {pic_url}")
        return pic_url
    
    async def extract_generic_video_info(self, element):
        """é€šç”¨è§†é¢‘ä¿¡æ¯æå–æ–¹æ³•ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        try:
            logger.debug("ä½¿ç”¨é€šç”¨æ–¹æ³•æå–è§†é¢‘ä¿¡æ¯...")
            
            # å¤šç§æ–¹å¼è·å–è§†é¢‘é“¾æ¥
            link_selectors = [
                'a[href*="/video/"]',
                'a[href*="BV"]',
                '.title a',
                '.video-title a',
                'a'
            ]
            
            link_element = None
            href = None
            
            for selector in link_selectors:
                link_element = await element.query_selector(selector)
                if link_element:
                    href = await link_element.get_attribute('href')
                    if href and '/video/' in href:
                        break
            
            if not href:
                logger.debug("é€šç”¨æ–¹æ³•æœªè·å–åˆ°è§†é¢‘é“¾æ¥")
                return None
            
            logger.debug(f"é€šç”¨æ–¹æ³•è·å–åˆ°è§†é¢‘é“¾æ¥: {href}")
            
            # æå–BVå·
            import re
            bv_match = re.search(r'/video/(BV[A-Za-z0-9]+)', href)
            if not bv_match:
                bv_match = re.search(r'(BV[A-Za-z0-9]+)', href)
                if not bv_match:
                    logger.debug(f"é€šç”¨æ–¹æ³•æ— æ³•ä»é“¾æ¥ä¸­æå–BVå·: {href}")
                    return None
            
            bvid = bv_match.group(1)
            logger.debug(f"é€šç”¨æ–¹æ³•æå–åˆ°BVå·: {bvid}")
            
            # å¤šç§æ–¹å¼è·å–æ ‡é¢˜
            title_selectors = [
                '.title',
                '.video-title', 
                'a[title]',
                '.name',
                '.video-name',
                'h3',
                '.title-text'
            ]
            
            title = ''
            for selector in title_selectors:
                title_element = await element.query_selector(selector)
                if title_element:
                    title = await title_element.get_attribute('title')
                    if not title:
                        title = await title_element.text_content()
                    if title and title.strip():
                        title = title.strip()
                        break
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨é“¾æ¥çš„titleå±æ€§
            if not title and link_element:
                title = await link_element.get_attribute('title') or ''
            
            logger.debug(f"é€šç”¨æ–¹æ³•æå–åˆ°æ ‡é¢˜: {title}")
            
            # å¤šç§æ–¹å¼è·å–å°é¢å›¾ç‰‡ - ä¼˜å…ˆä» img src è·å–
            img_selectors = [
                '.bili-cover-card__thumbnail img',  # ä¼˜å…ˆæŸ¥æ‰¾æ–°ç‰ˆå°é¢å¡ç‰‡
                'img',                              # é€šç”¨ img å…ƒç´ 
                '.cover img',                       # å°é¢åŒºåŸŸçš„ img
                '.pic img',                         # å›¾ç‰‡åŒºåŸŸçš„ img
                '.video-cover img',                 # è§†é¢‘å°é¢ img
                'picture img'                       # picture æ ‡ç­¾å†…çš„ img
            ]
            
            pic = ''
            for selector in img_selectors:
                img_element = await element.query_selector(selector)
                if img_element:
                    # ä¼˜å…ˆå°è¯• src å±æ€§ï¼Œç„¶åå°è¯•å…¶ä»–æ‡’åŠ è½½å±æ€§
                    pic = (await img_element.get_attribute('src') or 
                          await img_element.get_attribute('data-src') or 
                          await img_element.get_attribute('data-original') or
                          await img_element.get_attribute('lazy-src') or
                          await img_element.get_attribute('data-lazy-src') or
                          await img_element.get_attribute('srcset') or '')
                    
                    if pic:
                        # å¦‚æœæ˜¯ srcsetï¼Œå–ç¬¬ä¸€ä¸ª URL
                        if 'srcset' in str(pic):
                            pic = pic.split(',')[0].split(' ')[0]
                        
                        logger.debug(f"é€šç”¨æ–¹æ³•ä» '{selector}' è·å–å°é¢: {pic}")
                        break
                    else:
                        # å¦‚æœæ²¡æœ‰å¸¸è§„å±æ€§ï¼Œå°è¯•ä» style è·å–èƒŒæ™¯å›¾ç‰‡
                        style = await img_element.get_attribute('style') or ''
                        if 'background-image' in style:
                            import re
                            bg_match = re.search(r'background-image:\s*url\(["\']?([^"\')]+)', style)
                            if bg_match:
                                pic = bg_match.group(1)
                                logger.debug(f"é€šç”¨æ–¹æ³•ä» '{selector}' style è·å–å°é¢: {pic}")
                                break
            
            # ä½¿ç”¨ç»Ÿä¸€çš„å›¾ç‰‡URLå¤„ç†æ–¹æ³•
            pic = self.process_image_url(pic)
            logger.debug(f"é€šç”¨æ–¹æ³•å¤„ç†åçš„å°é¢URL: {pic}")
            
            # éªŒè¯å¿…è¦ä¿¡æ¯
            if bvid and title:
                video_info = {
                    'bvid': bvid,
                    'title': title.strip(),
                    'pic': pic,
                    'created': int(time.time())
                }
                logger.debug(f"é€šç”¨æ–¹æ³•æˆåŠŸæå–è§†é¢‘ä¿¡æ¯: {video_info}")
                return video_info
            else:
                logger.debug(f"é€šç”¨æ–¹æ³•ç¼ºå°‘å¿…è¦ä¿¡æ¯ - BVå·: {bvid}, æ ‡é¢˜: {title}")
                return None
                
        except Exception as e:
            logger.debug(f"é€šç”¨æ–¹æ³•æå–è§†é¢‘ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    async def get_user_videos(self, uid):
        """ä»ç”¨æˆ·è§†é¢‘é¡µé¢è·å–æ‰€æœ‰è§†é¢‘ä¿¡æ¯"""
        videos = []
        
        print(f"ğŸ“º å¼€å§‹ä»ç”¨æˆ·ç©ºé—´é¡µé¢è·å–è§†é¢‘åˆ—è¡¨...")
        
        for attempt in range(config.MAX_RETRIES):
            try:
                await self.smart_delay(is_api_request=True)
                
                # æ„å»ºç”¨æˆ·è§†é¢‘é¡µé¢URL
                video_url = config.USER_SPACE_URL.format(uid=uid)
                print(f"ğŸŒ è®¿é—®ç”¨æˆ·è§†é¢‘é¡µé¢: {video_url}")
                
                # è®¿é—®ç”¨æˆ·è§†é¢‘é¡µé¢
                response = await self.page.goto(video_url, wait_until="networkidle")
                
                if response.status != 200:
                    raise Exception(f"HTTP {response.status}")
                
                # ä½¿ç”¨æ–°çš„é¡µé¢ç­‰å¾…æœºåˆ¶
                if not await self.wait_for_page_fully_loaded("ç”¨æˆ·è§†é¢‘é¡µé¢"):
                    raise Exception("è§†é¢‘é¡µé¢åŠ è½½å¤±è´¥æˆ–å†…å®¹å¼‚å¸¸")
                
                # Debugæ—¥å¿—ï¼šæ˜¾ç¤ºè§†é¢‘é¡µé¢HTMLä¿¡æ¯
                if config.ENABLE_HTML_DEBUG and logger.isEnabledFor(logging.DEBUG):
                    page_content = await self.page.content()
                    html_preview = page_content[:config.HTML_DEBUG_MAX_LENGTH]
                    logger.debug(f"ç”¨æˆ·è§†é¢‘é¡µé¢HTMLå†…å®¹é¢„è§ˆ (å‰{config.HTML_DEBUG_MAX_LENGTH}å­—ç¬¦):\n{html_preview}")
                    logger.debug(f"è§†é¢‘é¡µé¢æ ‡é¢˜: {await self.page.title()}")
                    logger.debug(f"è§†é¢‘é¡µé¢URL: {self.page.url}")
                else:
                    page_content = await self.page.content()
                
                # æ£€æŸ¥é¡µé¢å†…å®¹
                if "ç”¨æˆ·ä¸å­˜åœ¨" in page_content or "è¯¥ç”¨æˆ·éšç§è®¾ç½®" in page_content:
                    print(f"âš ï¸ ç”¨æˆ· {uid} ä¸å­˜åœ¨æˆ–è®¾ç½®ä¸ºç§äºº")
                    return []
                
                if "æš‚æ— è§†é¢‘" in page_content or "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è§†é¢‘" in page_content:
                    print(f"ğŸ˜• ç”¨æˆ· {uid} æ²¡æœ‰å…¬å¼€è§†é¢‘")
                    return []
                
                # å¼€å§‹æ»šåŠ¨åŠ è½½æ›´å¤šè§†é¢‘
                videos = await self.scroll_and_collect_videos()
                
                if videos:
                    self.failure_count = 0  # æˆåŠŸåé‡ç½®å¤±è´¥è®¡æ•°
                    print(f"âœ… æˆåŠŸè·å–åˆ° {len(videos)} ä¸ªè§†é¢‘")
                    return videos
                else:
                    print(f"âš ï¸ æœªè·å–åˆ°ä»»ä½•è§†é¢‘")
                    return []
                    
            except Exception as e:
                if await self.handle_request_error(e, attempt):
                    continue
                if attempt < config.MAX_RETRIES - 1:
                    delay = config.RETRY_DELAY * (config.RETRY_BACKOFF ** attempt)
                    print(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•: {e}")
                    await asyncio.sleep(delay)
                else:
                    print(f"è·å–è§†é¢‘åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    return []
    
    async def download_user_videos(self, uid, download_covers=True):
        """ä¸‹è½½ç”¨æˆ·æ‰€æœ‰è§†é¢‘"""
        try:
            # åˆå§‹åŒ–æµè§ˆå™¨
            await self.initialize_browser()
            
            # åˆå§‹åŒ–è§†é¢‘ä¸‹è½½å™¨
            await self.init_video_downloader()
            
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = await self.get_user_info(uid)
            if not user_info:
                print(f"æ— æ³•è·å–ç”¨æˆ· {uid} çš„ä¿¡æ¯")
                return False
            
            user_name = user_info['name']
            print(f"ğŸ‘¤ ç”¨æˆ·: {user_name} (UID: {uid})")
            
            # è·å–ç”¨æˆ·æ‰€æœ‰è§†é¢‘
            videos = await self.get_user_videos(uid)
            if not videos:
                print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘")
                return False
            
            print(f"ğŸ“º æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
            
            # åˆ›å»ºä¿å­˜ç›®å½•
            safe_user_name = self.sanitize_filename(user_name)
            user_dir = Path(config.VIDEO_DOWNLOAD_CONFIG['output_dir']) / f"{uid}_{safe_user_name}"
            user_dir.mkdir(parents=True, exist_ok=True)
            
            # æ›´æ–°ä¸‹è½½å™¨è¾“å‡ºç›®å½•
            self.video_downloader.output_dir = user_dir
            
            print(f"ğŸ’¾ è§†é¢‘å°†ä¿å­˜åˆ°: {user_dir}")
            
            # ä¸‹è½½å°é¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if download_covers:
                cover_dir = user_dir / "covers"
                cover_dir.mkdir(exist_ok=True)
                print(f"\nğŸ–¼ï¸ å¼€å§‹ä¸‹è½½å°é¢...")
                await self.download_covers_for_videos(videos, cover_dir)
            
            # ä¸‹è½½è§†é¢‘
            print(f"\nğŸ“º å¼€å§‹ä¸‹è½½è§†é¢‘...")
            success_count = 0
            failed_videos = []
            
            with tqdm(total=len(videos), desc="ä¸‹è½½è§†é¢‘") as pbar:
                for video in videos:
                    bvid = video['bvid']
                    title = video['title']
                    
                    success = await self.video_downloader.download_video(bvid, title)
                    if success:
                        success_count += 1
                    else:
                        failed_videos.append(video)
                    
                    pbar.update(1)
                    pbar.set_postfix({"æˆåŠŸ": success_count, "å¤±è´¥": len(failed_videos)})
                    
                    # é˜²æ­¢è¯·æ±‚è¿‡äºé¢‘ç¹
                    await asyncio.sleep(random.uniform(2, 5))
            
            # è¾“å‡ºç»“æœç»Ÿè®¡
            print(f"\nğŸ‰ ä¸‹è½½å®Œæˆ!")
            print(f"ğŸ“Š æ€»è§†é¢‘æ•°: {len(videos)}")
            print(f"âœ… æˆåŠŸä¸‹è½½: {success_count}")
            print(f"âŒ å¤±è´¥æ•°é‡: {len(failed_videos)}")
            
            if failed_videos:
                print("\nå¤±è´¥çš„è§†é¢‘:")
                for video in failed_videos[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå¤±è´¥çš„
                    print(f"  - {video['bvid']}: {video['title']}")
                if len(failed_videos) > 10:
                    print(f"  ... è¿˜æœ‰ {len(failed_videos) - 10} ä¸ª")
                
                # ä¿å­˜å¤±è´¥è®°å½•
                failed_log = user_dir / "failed_videos.json"
                with open(failed_log, 'w', encoding='utf-8') as f:
                    json.dump(failed_videos, f, ensure_ascii=False, indent=2)
                print(f"å¤±è´¥è®°å½•å·²ä¿å­˜åˆ°: {failed_log}")
            
            return True
            
        finally:
            await self.close_browser()
    
    async def download_single_video(self, bvid):
        """ä¸‹è½½å•ä¸ªBVå·è§†é¢‘"""
        try:
            # åˆå§‹åŒ–è§†é¢‘ä¸‹è½½å™¨
            await self.init_video_downloader()
            
            print(f"ğŸ“º ä¸‹è½½å•ä¸ªè§†é¢‘: {bvid}")
            
            success = await self.video_downloader.download_video(bvid)
            
            if success:
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {bvid}")
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {bvid}")
            
            return success
            
        finally:
            await self.close_video_downloader()
    
    async def download_covers_for_videos(self, videos, cover_dir):
        """ä¸ºè§†é¢‘åˆ—è¡¨ä¸‹è½½å°é¢"""
        success_count = 0
        
        with tqdm(total=len(videos), desc="ä¸‹è½½å°é¢") as pbar:
            for video in videos:
                bvid = video['bvid']
                title = video['title']
                pic_url = video['pic']
                
                if not pic_url:
                    pbar.update(1)
                    continue
                
                # ç”Ÿæˆæ–‡ä»¶å
                safe_title = self.sanitize_filename(title)
                ext = self.get_image_extension(pic_url)
                filename = f"{bvid}_{safe_title}{ext}"
                save_path = cover_dir / filename
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if save_path.exists():
                    success_count += 1
                    pbar.update(1)
                    continue
                
                # ä¸‹è½½å°é¢
                if await self.download_cover(pic_url, save_path):
                    success_count += 1
                
                pbar.update(1)
                pbar.set_postfix({"æˆåŠŸ": success_count})
        
        print(f"âœ… å°é¢ä¸‹è½½å®Œæˆ: {success_count}/{len(videos)}")
    
    async def download_cover(self, pic_url, save_path):
        """ä¸‹è½½å•ä¸ªå°é¢å›¾ç‰‡"""
        for attempt in range(config.MAX_RETRIES):
            try:
                await self.smart_delay(is_api_request=False)
                
                # ç¡®ä¿URLæ˜¯å®Œæ•´çš„
                if pic_url.startswith('//'):
                    pic_url = 'https:' + pic_url
                elif pic_url.startswith('/'):
                    pic_url = 'https://i0.hdslb.com' + pic_url
                
                # ä½¿ç”¨é¡µé¢å‘èµ·è¯·æ±‚ä¸‹è½½å›¾ç‰‡
                response = await self.page.goto(pic_url)
                
                if response.status != 200:
                    raise Exception(f"HTTP {response.status}")
                
                # è·å–å›¾ç‰‡æ•°æ®
                image_data = await response.body()
                
                # åˆ›å»ºç›®å½•
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                with open(save_path, 'wb') as f:
                    f.write(image_data)
                
                # æˆåŠŸä¸‹è½½åå‡å°‘å¤±è´¥è®¡æ•°
                if self.failure_count > 0:
                    self.failure_count = max(0, self.failure_count - 1)
                
                return True
                
            except Exception as e:
                if await self.handle_request_error(e, attempt):
                    continue
                if attempt < config.MAX_RETRIES - 1:
                    delay = config.RETRY_DELAY * (config.RETRY_BACKOFF ** attempt)
                    print(f"ä¸‹è½½å¤±è´¥ï¼Œ{delay}ç§’åç¬¬ {attempt + 2} æ¬¡é‡è¯•: {e}")
                    await asyncio.sleep(delay)
                else:
                    print(f"ä¸‹è½½å¤±è´¥ï¼Œå·²é‡è¯• {config.MAX_RETRIES} æ¬¡: {e}")
                    return False
        
        return False
    
    def get_image_extension(self, pic_url):
        """ä»URLè·å–å›¾ç‰‡æ‰©å±•å"""
        try:
            parsed = urlparse(pic_url)
            path = parsed.path
            _, ext = os.path.splitext(path)
            if ext.lower() in config.ALLOWED_IMAGE_FORMATS:
                return ext
            else:
                return '.jpg'  # é»˜è®¤æ‰©å±•å
        except:
            return '.jpg'
    
    async def crawl_user_covers(self, uid):
        """çˆ¬å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘å°é¢"""
        try:
            # åˆå§‹åŒ–æµè§ˆå™¨
            await self.initialize_browser()
            
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = await self.get_user_info(uid)
            if not user_info:
                print(f"æ— æ³•è·å–ç”¨æˆ· {uid} çš„ä¿¡æ¯")
                return False
            
            user_name = user_info['name']
            print(f"ç”¨æˆ·: {user_name} (UID: {uid})")
            
            # è·å–ç”¨æˆ·æ‰€æœ‰è§†é¢‘
            videos = await self.get_user_videos(uid)
            if not videos:
                print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘")
                return False
            
            # åˆ›å»ºä¿å­˜ç›®å½•
            safe_user_name = self.sanitize_filename(user_name)
            save_dir = Path(f"{uid}_{safe_user_name}")
            save_dir.mkdir(exist_ok=True)
            
            print(f"å°é¢å°†ä¿å­˜åˆ°ç›®å½•: {save_dir}")
            
            # ä¸‹è½½å°é¢
            success_count = 0
            failed_videos = []
            
            with tqdm(total=len(videos), desc="ä¸‹è½½å°é¢") as pbar:
                for video in videos:
                    bvid = video['bvid']
                    title = video['title']
                    pic_url = video['pic']
                    
                    if not pic_url:
                        print(f"è§†é¢‘ {bvid} æ²¡æœ‰å°é¢URL")
                        failed_videos.append(video)
                        pbar.update(1)
                        continue
                    
                    # ç”Ÿæˆæ–‡ä»¶å
                    safe_title = self.sanitize_filename(title)
                    ext = self.get_image_extension(pic_url)
                    filename = f"{bvid}_{safe_title}{ext}"
                    save_path = save_dir / filename
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                    if save_path.exists():
                        print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}")
                        success_count += 1
                        pbar.update(1)
                        continue
                    
                    # ä¸‹è½½å°é¢
                    if await self.download_cover(pic_url, save_path):
                        success_count += 1
                        pbar.set_postfix({"æˆåŠŸ": success_count, "å¤±è´¥": len(failed_videos)})
                    else:
                        failed_videos.append(video)
                    
                    pbar.update(1)
            
            # è¾“å‡ºç»“æœç»Ÿè®¡
            print(f"\nä¸‹è½½å®Œæˆ!")
            print(f"æ€»è§†é¢‘æ•°: {len(videos)}")
            print(f"æˆåŠŸä¸‹è½½: {success_count}")
            print(f"å¤±è´¥æ•°é‡: {len(failed_videos)}")
            
            if failed_videos:
                print("\nå¤±è´¥çš„è§†é¢‘:")
                for video in failed_videos[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå¤±è´¥çš„
                    print(f"  - {video['bvid']}: {video['title']}")
                if len(failed_videos) > 10:
                    print(f"  ... è¿˜æœ‰ {len(failed_videos) - 10} ä¸ª")
            
            # ä¿å­˜å¤±è´¥è®°å½•
            if failed_videos:
                failed_log = save_dir / "failed_downloads.json"
                with open(failed_log, 'w', encoding='utf-8') as f:
                    json.dump(failed_videos, f, ensure_ascii=False, indent=2)
                print(f"å¤±è´¥è®°å½•å·²ä¿å­˜åˆ°: {failed_log}")
            
            return True
            
        finally:
            # ç¡®ä¿å…³é—­æµè§ˆå™¨
            await self.close_browser()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ­ å“”å“©å“”å“©è§†é¢‘çˆ¬è™« (Playwrightç‰ˆæœ¬ - æ”¯æŒå°é¢å’Œè§†é¢‘ä¸‹è½½)")
    print("=" * 65)
    print("\nğŸŒŸ åŠŸèƒ½ç‰¹è‰²:")
    print("- ğŸ–¼ï¸ å°é¢ä¸‹è½½ - æ‰¹é‡ä¸‹è½½ç”¨æˆ·æ‰€æœ‰è§†é¢‘å°é¢")
    print("- ğŸ“º è§†é¢‘ä¸‹è½½ - æ”¯æŒä¸‹è½½ç”¨æˆ·æ‰€æœ‰è§†é¢‘æˆ–å•ä¸ªBVå·")
    print("- ğŸ­ çœŸå®æµè§ˆå™¨ - ä½¿ç”¨Playwrighté™ä½è¢«æ£€æµ‹é£é™©")
    print("- ğŸ›¡ï¸ æ™ºèƒ½åçˆ¬ - è‡ªåŠ¨å¤„ç†å„ç§åçˆ¬è™«é™åˆ¶")
    print("- ğŸ“„ åˆ†é¡µæ”¯æŒ - è‡ªåŠ¨å¤„ç†å¤šé¡µè§†é¢‘è·å–")
    print("- ğŸ” æ•°é‡æ ¡éªŒ - ç¡®ä¿è§†é¢‘æ”¶é›†å®Œæ•´æ€§")
    print("- ğŸ¬ åˆ†æ®µåˆå¹¶ - è‡ªåŠ¨ä¸‹è½½å¹¶åˆå¹¶è§†é¢‘éŸ³é¢‘æµ")
    print("\nâš™ï¸ å½“å‰é…ç½®:")
    print(f"- ğŸ• è¯·æ±‚é—´éš”: {config.REQUEST_DELAY_MIN}-{config.REQUEST_DELAY_MAX}ç§’")
    print(f"- ğŸ“¥ ä¸‹è½½é—´éš”: {config.DOWNLOAD_DELAY_MIN}-{config.DOWNLOAD_DELAY_MAX}ç§’")
    print(f"- ğŸ”„ è¿ç»­è¯·æ±‚é™åˆ¶: {config.MAX_CONSECUTIVE_REQUESTS}æ¬¡")
    print(f"- ğŸ’¤ ä¼‘æ¯æ—¶é—´: {config.LONG_BREAK_DURATION}ç§’")
    print(f"- ğŸ“„ åˆ†é¡µåŠŸèƒ½: {'å¼€å¯' if config.PAGINATION_CONFIG.get('enabled', False) else 'å…³é—­'}")
    print(f"- ğŸ” æ•°é‡æ ¡éªŒ: {'å¼€å¯' if config.CONTENT_VERIFICATION.get('verify_video_count', False) else 'å…³é—­'}")
    print(f"- ğŸ“º è§†é¢‘ä¸‹è½½: {'å¼€å¯' if config.VIDEO_DOWNLOAD_CONFIG.get('enabled', False) else 'å…³é—­'}")
    print(f"- ğŸ“ æ—¥å¿—çº§åˆ«: {logging.getLevelName(config.LOG_LEVEL)}")
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger.info("ç¨‹åºå¯åŠ¨ï¼Œå½“å‰é…ç½®å·²åŠ è½½")
    logger.debug(f"è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼ŒHTMLè°ƒè¯•: {config.ENABLE_HTML_DEBUG}")
    
    import sys
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='å“”å“©å“”å“©è§†é¢‘çˆ¬è™« - æ”¯æŒå°é¢ä¸‹è½½å’Œè§†é¢‘ä¸‹è½½',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹ç”¨æ³•:
  # ä¸‹è½½ç”¨æˆ·å°é¢ï¼ˆé»˜è®¤ï¼‰
  python %(prog)s 123456
  
  # ä¸‹è½½ç”¨æˆ·æ‰€æœ‰è§†é¢‘
  python %(prog)s 123456 --download-videos
  
  # ä¸‹è½½ç”¨æˆ·è§†é¢‘ï¼Œä¸ä¸‹è½½å°é¢
  python %(prog)s 123456 --download-videos --no-covers
  
  # ä»…ä¸‹è½½å°é¢
  python %(prog)s 123456 --covers-only
  
  # ä¸‹è½½å•ä¸ªBVå·è§†é¢‘
  python %(prog)s --bv BV1234567890
  
  # äº¤äº’æ¨¡å¼
  python %(prog)s
        '''
    )
    
    parser.add_argument('uid', nargs='?', type=int, help='ç”¨æˆ·UID')
    parser.add_argument('--bv', '--bvid', type=str, help='ä¸‹è½½æŒ‡å®šBVå·çš„è§†é¢‘')
    parser.add_argument('--download-videos', action='store_true', help='ä¸‹è½½ç”¨æˆ·æ‰€æœ‰è§†é¢‘')
    parser.add_argument('--covers-only', action='store_true', help='ä»…ä¸‹è½½å°é¢ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰')
    parser.add_argument('--no-covers', action='store_true', help='ä¸ä¸‹è½½å°é¢ï¼ˆä¸--download-videosé…åˆä½¿ç”¨ï¼‰')
    parser.add_argument('--enable-video-download', action='store_true', help='å¯ç”¨è§†é¢‘ä¸‹è½½åŠŸèƒ½')
    
    args = parser.parse_args()
    
    # å¤„ç†BVå·ä¸‹è½½
    if args.bv:
        bvid = args.bv
        if not bvid.startswith('BV'):
            bvid = 'BV' + bvid
        
        print(f"ğŸ“º ä¸‹è½½å•ä¸ªè§†é¢‘: {bvid}")
        
        crawler = PlaywrightBilibiliCrawler()
        try:
            success = await crawler.download_single_video(bvid)
            if success:
                print("\nğŸ‰ è§†é¢‘ä¸‹è½½å®Œæˆï¼")
            else:
                print("\nğŸ˜” è§†é¢‘ä¸‹è½½å¤±è´¥ï¼")
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
        except Exception as e:
            print(f"\nğŸ˜± ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        return
    
    # è·å–UID
    uid = args.uid
    if not uid:
        # äº¤äº’æ¨¡å¼
        while True:
            uid_input = input("\nğŸ¯ è¯·è¾“å…¥è¦çˆ¬å–çš„ç”¨æˆ·UID (æˆ–è€…è¾“å…¥ 'q' é€€å‡º): ").strip()
            if uid_input.lower() == 'q':
                print("ğŸ™‹â€â™‚ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return
            if uid_input.isdigit():
                uid = int(uid_input)
                break
            else:
                print("ğŸ˜… è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—UID")
    
    # ç¡®å®šæ“ä½œæ¨¡å¼
    download_videos = args.download_videos or args.enable_video_download
    download_covers = not args.no_covers  # é»˜è®¤ä¸‹è½½å°é¢ï¼Œé™¤éæ˜ç¡®æŒ‡å®šä¸ä¸‹è½½
    
    # å¦‚æœå¯ç”¨äº†è§†é¢‘ä¸‹è½½åŠŸèƒ½ï¼Œéœ€è¦å…ˆå¯ç”¨é…ç½®
    if download_videos:
        config.VIDEO_DOWNLOAD_CONFIG['enabled'] = True
        print("\nğŸ“º å·²å¯ç”¨è§†é¢‘ä¸‹è½½åŠŸèƒ½")
    
    # æ˜¾ç¤ºæ“ä½œä¿¡æ¯
    print(f"\nğŸ“‹ æ“ä½œæ¨¡å¼:")
    print(f"  - ç”¨æˆ·UID: {uid}")
    print(f"  - ä¸‹è½½å°é¢: {'æ˜¯' if download_covers else 'å¦'}")
    print(f"  - ä¸‹è½½è§†é¢‘: {'æ˜¯' if download_videos else 'å¦'}")
    
    # ç¡®è®¤ç»§ç»­
    action_desc = []
    if download_covers: action_desc.append("å°é¢")
    if download_videos: action_desc.append("è§†é¢‘")
    action_text = "å’Œ".join(action_desc) if action_desc else "æ•°æ®"
    
    confirm = input(f"\nğŸš€ å³å°†çˆ¬å–ç”¨æˆ· {uid} çš„{action_text}ï¼Œç»§ç»­å—? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes', 'æ˜¯']:
        print("ğŸ™‹â€â™‚ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹å¹¶å¼€å§‹çˆ¬å–
    crawler = PlaywrightBilibiliCrawler()
    
    try:
        if download_videos:
            # è§†é¢‘ä¸‹è½½æ¨¡å¼
            success = await crawler.download_user_videos(uid, download_covers=download_covers)
        else:
            # ä»…å°é¢ä¸‹è½½æ¨¡å¼
            success = await crawler.crawl_user_covers(uid)
        
        if success:
            print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        else:
            print("\nğŸ˜” ä»»åŠ¡å¤±è´¥ï¼")
            print("\nğŸ’¡ å»ºè®®:")
            print("1. æ£€æŸ¥UIDæ˜¯å¦æ­£ç¡®")
            print("2. ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š")
            print("3. å¦‚æœä¸‹è½½è§†é¢‘ï¼Œè¯·ç¡®ä¿å·²å®‰è£…FFmpeg")
            print("4. ç¨åå†è¯•")
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
        print("ğŸ’¾ å·²ä¸‹è½½çš„æ–‡ä»¶å°†ä¿ç•™ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨è·³è¿‡")
    except Exception as e:
        print(f"\nğŸ˜± ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        print("\nğŸ› ï¸ æ•…éšœæ’é™¤:")
        print("1. ç¡®ä¿å·²å®‰è£…Playwright: pip install playwright")
        print("2. ç¡®ä¿å·²å®‰è£…æµè§ˆå™¨: playwright install chromium")
        print("3. å¦‚æœä¸‹è½½è§†é¢‘ï¼Œç¡®ä¿å·²å®‰è£…FFmpeg")
        print("4. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("5. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())